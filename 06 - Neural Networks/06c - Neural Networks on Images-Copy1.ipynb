{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5a6deb-3b06-4b1a-8084-eaec28995882",
   "metadata": {
    "id": "2a5a6deb-3b06-4b1a-8084-eaec28995882"
   },
   "source": [
    "# Neural Networks on Image Dataset\n",
    "\n",
    "In this notebook, we tackle a simple image classification dataset from sklearn: the digits dataset (handwritten digits images). For this exercise, we need the `torchvision` library. To install it, simply use the following installation command,\n",
    "\n",
    "```shell\n",
    "pip install torchvision\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05402ef6-38ca-47d4-8275-e76360f17f07",
   "metadata": {
    "id": "05402ef6-38ca-47d4-8275-e76360f17f07"
   },
   "source": [
    "## Instructions for All Labs\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* Some markdown cells contain questions.\n",
    "  * For questions <span style=\"color:red;\">colored in red</span>, you must submit your answers in the corresponding Assignment in the course page. Make sure that you enter your responses in the item with the matching question code. Answers that do not follow the prescribed format will automatically be marked wrong by the checker.\n",
    "  * For questions <span style=\"color:green;\">colored in green</span>, you don't have to submit your answers, but you must think about these questions as they will help enrich your understanding of the concepts covered in the labs.\n",
    "* You are expected to search how to some functions work on the Internet or via the docs.\n",
    "* You may add new cells for \"scrap work\".\n",
    "* The notebooks will undergo a \"Restart and Run All\" command, so make sure that your code is working properly.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3c645b-8dae-4d3d-b3e5-5fbcfde98fbe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b3c645b-8dae-4d3d-b3e5-5fbcfde98fbe",
    "outputId": "f7fe7a29-c750-4ae2-ebfd-efc05408c3a7"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m  \u001b[38;5;66;03m# pip install seaborn\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_digits\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(torchvision\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torchvision\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torchvision\\_meta_registrations.py:26\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroi_align\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torchvision\\_meta_registrations.py:18\u001b[0m, in \u001b[0;36mregister_meta.<locals>.wrapper\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(fn):\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[38;5;241m.\u001b[39m_has_ops():\n\u001b[0;32m     19\u001b[0m         get_meta_lib()\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchvision, op_name), overload_name), fn)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns  # pip install seaborn\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbea4db3-1e53-4aa9-8be9-ed2caa1b1e8a",
   "metadata": {
    "id": "dbea4db3-1e53-4aa9-8be9-ed2caa1b1e8a"
   },
   "source": [
    "Set the seed for PRNG and determinism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799b3ae-ab56-470d-8605-b04c1e2afb03",
   "metadata": {
    "id": "a799b3ae-ab56-470d-8605-b04c1e2afb03"
   },
   "outputs": [],
   "source": [
    "seed = 73\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4918d82-f392-4361-8b62-45a05df7c800",
   "metadata": {
    "id": "a4918d82-f392-4361-8b62-45a05df7c800"
   },
   "source": [
    "Define the function for plotting a given set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd5d76-7497-4b10-9663-4c286b6c02b2",
   "metadata": {
    "id": "02bd5d76-7497-4b10-9663-4c286b6c02b2"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "def show(images: List) -> None:\n",
    "    _, axs = plt.subplots(ncols=len(images), squeeze=False)\n",
    "    for index, image in enumerate(images):\n",
    "        image = image.detach()\n",
    "        axs[0, index].imshow(np.asarray(image), cmap=\"gray\")\n",
    "        axs[0, index].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8831a50-b6de-4cdc-a643-8161d7874082",
   "metadata": {
    "id": "d8831a50-b6de-4cdc-a643-8161d7874082"
   },
   "source": [
    "Load the digits dataset which consists of the features $X$ and labels $y$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba4258-2a89-4195-95a9-3e10ca5dabf8",
   "metadata": {
    "id": "ccba4258-2a89-4195-95a9-3e10ca5dabf8"
   },
   "outputs": [],
   "source": [
    "images, labels = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c6768e-5078-4618-9d6e-d7213117d09c",
   "metadata": {
    "id": "b9c6768e-5078-4618-9d6e-d7213117d09c"
   },
   "source": [
    "Check the shape of the images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e69f1d-bf7b-461a-bff0-c4e7810cac1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08e69f1d-bf7b-461a-bff0-c4e7810cac1a",
    "outputId": "7e2963dd-d8c7-4293-bb89-9a11ec4f57ed"
   },
   "outputs": [],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea3e3f-0df3-46a1-8672-1d411a88cda9",
   "metadata": {
    "id": "3fea3e3f-0df3-46a1-8672-1d411a88cda9"
   },
   "source": [
    "Check samples of the images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20040e1e-b21b-462e-91f2-ffe981546d09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20040e1e-b21b-462e-91f2-ffe981546d09",
    "outputId": "88b151dc-fc65-46bd-d831-7e600c6a6379"
   },
   "outputs": [],
   "source": [
    "print(images[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80ce7e-30cb-454b-85dd-3944e9dced99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f80ce7e-30cb-454b-85dd-3944e9dced99",
    "outputId": "fbaca842-fd3e-4599-85d1-445b854923b1"
   },
   "outputs": [],
   "source": [
    "print(labels[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387f32e-b777-4f00-a60d-153d3f3b5c32",
   "metadata": {
    "id": "8387f32e-b777-4f00-a60d-153d3f3b5c32"
   },
   "source": [
    "From here, we can see that there are 1,797 instances of images and labels. However, we can see that each \"image\" has 1x64 vectors.\n",
    "\n",
    "Meanwhile, an image is supposed to have a width x length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a9f6a-a8b7-4dcb-9545-50709c84b906",
   "metadata": {
    "id": "3e4a9f6a-a8b7-4dcb-9545-50709c84b906"
   },
   "outputs": [],
   "source": [
    "# to do: reshape the `images` tensor to be of `num_instances x width x length` shape\n",
    "images = images.reshape(-1,8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e123e8e9-9c14-4a94-ada7-78467268ece2",
   "metadata": {
    "id": "e123e8e9-9c14-4a94-ada7-78467268ece2"
   },
   "source": [
    "Retrieve the only first 5 images for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b212e3-9c93-4e48-9990-a95820e6f7c1",
   "metadata": {
    "id": "51b212e3-9c93-4e48-9990-a95820e6f7c1"
   },
   "outputs": [],
   "source": [
    "# to do: retrieve the first 5 images\n",
    "tensor = torch.tensor(images[:5]).unsqueeze(1).reshape(5,8,8)\n",
    "image_grid = torchvision.utils.make_grid(tensor,nrow=5,pad_value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6dc487-fe82-4c56-a588-d8e6f4db8826",
   "metadata": {
    "id": "6f6dc487-fe82-4c56-a588-d8e6f4db8826"
   },
   "source": [
    "Check that we got the first 5 items and that the images have been properly reshaped. It should have a shape of 5x8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b166b-09cb-4a77-a660-f748023b78a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d30b166b-09cb-4a77-a660-f748023b78a8",
    "outputId": "fdddfba6-48ee-44c7-8df0-c5a9447dbc5f"
   },
   "outputs": [],
   "source": [
    "image_grid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b14b542-a5fe-461d-a7fc-6dc7646284c2",
   "metadata": {
    "id": "1b14b542-a5fe-461d-a7fc-6dc7646284c2"
   },
   "source": [
    "Each image having a shape of 8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db90a7-27d7-42a5-be14-d0c14eaf5e5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34db90a7-27d7-42a5-be14-d0c14eaf5e5b",
    "outputId": "2043ca0e-ccb7-48fb-be9b-a4dc0fe1021d"
   },
   "outputs": [],
   "source": [
    "image_grid[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329fac0-887e-4486-b52e-e1d658baf2ce",
   "metadata": {
    "id": "2329fac0-887e-4486-b52e-e1d658baf2ce"
   },
   "source": [
    "Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2118f19-7427-4f09-a586-a3c586874877",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "e2118f19-7427-4f09-a586-a3c586874877",
    "outputId": "42dbec55-efa7-41bd-c644-65e54c772f1d"
   },
   "outputs": [],
   "source": [
    "show(image_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb040b-cd65-4864-be8b-66a7f10e8df2",
   "metadata": {
    "id": "67bb040b-cd65-4864-be8b-66a7f10e8df2"
   },
   "source": [
    "Confirm the labels of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd37399-db92-43ed-bf08-c0ace0fa2873",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dd37399-db92-43ed-bf08-c0ace0fa2873",
    "outputId": "5f52faa0-02a5-4356-d4c1-65e3f86152e0"
   },
   "outputs": [],
   "source": [
    "# to do: print the labels\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa522d7-9ce8-4d7b-889f-7f3427020f4f",
   "metadata": {
    "id": "6aa522d7-9ce8-4d7b-889f-7f3427020f4f"
   },
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "We split the images and labels to training/validation/test sets. The splitting is as follows,\n",
    "\n",
    "* Training: 80%\n",
    "* Test: 20%\n",
    "\n",
    "Then we get the 20% of the training set as the validation set, leaving us with the following,\n",
    "\n",
    "* Training: 64%\n",
    "* Validation: 16%\n",
    "* Test: 20%\n",
    "\n",
    "Recall that we reshaped our images to be of $num\\_instances \\times width \\times length$ shape.\n",
    "\n",
    "So, we have to reshape it back to $num\\_instances \\times dimensions$ before splitting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91b85e-5f19-4769-9e82-95f0c4fbe933",
   "metadata": {
    "id": "aa91b85e-5f19-4769-9e82-95f0c4fbe933"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images = images.reshape(images.shape[0], -1)\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=2e-1, stratify=labels, shuffle=True, random_state=seed\n",
    ")\n",
    "\n",
    "train_features, validation_features, train_labels, validation_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=2e-1,\n",
    "    stratify=train_labels,\n",
    "    shuffle=True,\n",
    "    random_state=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb333ce-5d9d-4021-a377-e3bb25962b99",
   "metadata": {
    "id": "4cb333ce-5d9d-4021-a377-e3bb25962b99"
   },
   "source": [
    "Confirm the dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b69ef3-a453-4458-aecd-4f55281e3fdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26b69ef3-a453-4458-aecd-4f55281e3fdc",
    "outputId": "2af105af-8a19-498f-ca7e-3083509a6850"
   },
   "outputs": [],
   "source": [
    "# to do: print the dataset sizes\n",
    "print(f\"Dataset sizes:\")\n",
    "print(\n",
    "    #we get the actual count of elements in our train featurses, validation features and in our test set\n",
    "    f\"\\tTraining: {len(train_features)}, Validation: {len(validation_features)}, Test: {len(test_features)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c0b8a-f279-4cdb-aef6-73bc9af81595",
   "metadata": {
    "id": "201c0b8a-f279-4cdb-aef6-73bc9af81595"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-19:** How many instances are there in the training, validation, and test sets respectively?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0113a54-3502-402a-98ec-4f42af80376c",
   "metadata": {
    "id": "201c0b8a-f279-4cdb-aef6-73bc9af81595"
   },
   "source": [
    "**Answer**: Training = 1149\n",
    "Validation = 288\n",
    "Test set = 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c657da0-3b65-4e5a-9b58-2a0201c67c72",
   "metadata": {
    "id": "1c657da0-3b65-4e5a-9b58-2a0201c67c72"
   },
   "source": [
    "After splitting the dataset into training/validation/test sets, we can now pack them into PyTorch tensor objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f189ab-c806-478d-8e96-2a1aa4bb769a",
   "metadata": {
    "id": "40f189ab-c806-478d-8e96-2a1aa4bb769a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mtrain_features\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m      2\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(train_labels)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# to do: pack the validation and test data into torch tensors.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "train_features = torch.from_numpy(train_features).float()\n",
    "train_labels = torch.from_numpy(train_labels)\n",
    "\n",
    "# to do: pack the validation and test data into torch tensors.\n",
    "validation_features = torch.from_numpy(validation_features).float()\n",
    "validation_labels = torch.from_numpy(validation_labels)\n",
    "\n",
    "test_features = torch.from_numpy(test_features).float()\n",
    "test_labels = torch.from_numpy(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e73e2-8e4c-4c8c-af2b-494a5acdea6f",
   "metadata": {
    "id": "878e73e2-8e4c-4c8c-af2b-494a5acdea6f"
   },
   "source": [
    "For these data to be ingestible for our model, we have to pack them into a [TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset) objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27581a8-9b3c-437b-ad6e-c00510ead45c",
   "metadata": {
    "id": "d27581a8-9b3c-437b-ad6e-c00510ead45c"
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "\n",
    "# to do: pack the validation and test features and labels into a TensorDataset\n",
    "validation_dataset = torch.utils.data.TensorDataset(validation_features, validation_labels)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed870926-8d0f-4cd6-beaa-2df33df8119d",
   "metadata": {
    "id": "ed870926-8d0f-4cd6-beaa-2df33df8119d"
   },
   "source": [
    "To automate the batching of the datasets during training, we pack them into [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764a1c4-1595-483b-bd9c-9b7b8675f826",
   "metadata": {
    "id": "5764a1c4-1595-483b-bd9c-9b7b8675f826"
   },
   "outputs": [],
   "source": [
    "# define the batch size\n",
    "batch_size = 100\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "# to do: pack the datasets into data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=multiprocessing.cpu_count(),\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=len(validation_dataset),\n",
    "    num_workers=multiprocessing.cpu_count(),\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=len(test_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec46a347-b4ab-448e-b3e7-d395af3059cd",
   "metadata": {
    "id": "ec46a347-b4ab-448e-b3e7-d395af3059cd"
   },
   "source": [
    "## Image Classifier (baseline)\n",
    "\n",
    "Implement an image classifier neural network with the following specifications,\n",
    "\n",
    "* 2 layers with each layer having 500 neurons each\n",
    "* Each hidden layer will use logistic/sigmoid function as its activation function\n",
    "* Use SGD as the optimization algorithm with learning rate $1 \\times 10^{-3}$\n",
    "\n",
    "Train for 50 epochs with mini-batch size 100. This will serve as our baseline model, which uses logistic/sigmoid function to learn the nonlinear relationships in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81b523-01dd-4c1d-8722-85ddd7b82861",
   "metadata": {
    "id": "7a81b523-01dd-4c1d-8722-85ddd7b82861"
   },
   "outputs": [],
   "source": [
    "class ClassifierA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # to do: define the hidden layers\n",
    "        self.hidden1 = torch.nn.Linear(64, 500)\n",
    "        self.hidden2 = torch.nn.Linear(500, 500)\n",
    "        self.output = torch.nn.Linear(500, 10)\n",
    "        \n",
    "        # to do: define the classification layer\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        # to do: define the forward pass function\n",
    "        x = self.sigmoid(self.hidden1(features))\n",
    "        x = self.sigmoid(self.hidden2(x))\n",
    "        logits = self.output(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e7ec6-3290-418e-9797-240e657d6426",
   "metadata": {
    "id": "056e7ec6-3290-418e-9797-240e657d6426"
   },
   "source": [
    "For convenience, we define a training function for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef131a1-b8fc-4314-a986-81ea6cb7e60e",
   "metadata": {
    "id": "3ef131a1-b8fc-4314-a986-81ea6cb7e60e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    validation_loader: torch.utils.data.DataLoader,\n",
    "    epochs: int = 50,\n",
    "    learning_rate: float = 1e-2,\n",
    "    display_interval: int = 5\n",
    ") -> Tuple[List, List, List, List]:\n",
    "\n",
    "    # to do:\n",
    "    # set the learning rate, pass the model parameters to be optimized\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_acc = list()\n",
    "    train_loss = list()\n",
    "    validation_acc = list()\n",
    "    validation_loss = list()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_loss = list()\n",
    "        epoch_acc = list()\n",
    "        \n",
    "        for features_batch, labels_batch in train_loader:\n",
    "            # to do: zero out the gradients to prevent gradient accumulation\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # to do: switch the features to GPU\n",
    "            features_batch = features_batch.to(device)\n",
    "            labels_batch = labels_batch.cuda().long()\n",
    "\n",
    "            # to do: compute model predictions\n",
    "            logits = model(features_batch)\n",
    "\n",
    "            # to do: compute the loss\n",
    "            loss = criterion(logits, labels_batch)\n",
    "\n",
    "            # to do: compute accuracy of predictions in [0, 1] range\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            acc = (predictions == labels_batch).float().mean().item()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            train_acc.append(acc)\n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_acc.append(acc)\n",
    "\n",
    "            # to do: run backprop\n",
    "            loss.backward()\n",
    "\n",
    "            # to do: optimize the weights based on backpropagated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for features_batch, labels_batch in validation_loader:\n",
    "                    # to do: switch the features and labels to GPU\n",
    "                    features_batch = features_batch.to(device)\n",
    "                    labels_batch = labels_batch.cuda().long()\n",
    "\n",
    "                    # to do: compute the model predictions\n",
    "                    logits = model(features_batch)\n",
    "\n",
    "                    # to do: compute the loss\n",
    "                    loss = criterion(logits, labels_batch)\n",
    "\n",
    "                    # to do: compute the model predictions accuracy in [0, 1] range\n",
    "                    predictions = torch.argmax(logits, dim=1)\n",
    "                    acc = (predictions == labels_batch).float().mean().item()\n",
    "\n",
    "                    validation_loss.append(loss.item())\n",
    "                    validation_acc.append(acc)\n",
    "\n",
    "            # to do: enable training mode again\n",
    "            model.train()\n",
    "\n",
    "        if (epoch + 1) % display_interval == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "            print(\n",
    "                f\"\\tTraining Loss:  {np.mean(epoch_loss):.4f}, Training Acc: {np.mean(epoch_acc):.4f}\"\n",
    "            )\n",
    "            print(f\"\\tValidation Loss: {loss.item():.4f}, Validation Acc: {acc:.4f}\")\n",
    "\n",
    "    return train_acc, train_loss, validation_acc, validation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f9c19e-5354-407d-8c5f-b2cc0d87ca95",
   "metadata": {
    "id": "20f9c19e-5354-407d-8c5f-b2cc0d87ca95"
   },
   "source": [
    "We also prepare an evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59991d4-38b9-456f-a804-7d6d70acf410",
   "metadata": {
    "id": "e59991d4-38b9-456f-a804-7d6d70acf410"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: torch.nn.Module, data_loader: torch.utils.data.DataLoader\n",
    ") -> float:\n",
    "    # Disable gradient computation for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Switch to CPU for computations\n",
    "        device = torch.device(\"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for features_batch, labels_batch in data_loader:\n",
    "            # Move features and labels to CPU\n",
    "            features_batch = features_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device).long()\n",
    "\n",
    "            # Compute model predictions\n",
    "            logits = model(features_batch)\n",
    "\n",
    "            # Get predicted labels\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "            # Compute accuracy\n",
    "            correct += (predictions == labels_batch).sum().item()\n",
    "            total += labels_batch.size(0)\n",
    "\n",
    "    acc = correct / total  # Accuracy in [0,1] range\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740b910-9228-42a8-a0d4-ef9579b67da3",
   "metadata": {
    "id": "3740b910-9228-42a8-a0d4-ef9579b67da3"
   },
   "source": [
    "Initialize the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7239a-b632-4088-896f-112e460efaef",
   "metadata": {
    "id": "bcb7239a-b632-4088-896f-112e460efaef"
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "baseline_model = ClassifierA()\n",
    "\n",
    "# switch to GPU for computation\n",
    "device = torch.device(\"cuda\" \n",
    "                      if torch.cuda.is_available() \n",
    "                      else \"cpu\")\n",
    "baseline_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb3708-26f0-4296-bcb0-c442a8669461",
   "metadata": {
    "id": "84eb3708-26f0-4296-bcb0-c442a8669461"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-20:** What is the summation of the initial weight parameters for class 0 in the `baseline_model`?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10438ed5-34a2-4e97-ae21-2401a69b96b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10438ed5-34a2-4e97-ae21-2401a69b96b6",
    "outputId": "630df493-cd36-4140-c15a-7ef1510cfb33"
   },
   "outputs": [],
   "source": [
    "output_layer = baseline_model.output.weight\n",
    "weights_class = output_layer[0]\n",
    "sum_weights = weights_class.sum().item()\n",
    "\n",
    "print(sum_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb61e40e-2e82-4659-b44d-5fd6695be2bc",
   "metadata": {
    "id": "cb61e40e-2e82-4659-b44d-5fd6695be2bc"
   },
   "source": [
    "**Answer**: -0.11486731469631195"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff46f5-c0da-4992-be93-36f69974d65e",
   "metadata": {
    "id": "81ff46f5-c0da-4992-be93-36f69974d65e"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-21:** What is the summation of the initial weight parameters for class 9 in the `baseline_model`?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52314f-cf8f-4851-96f5-7ebdbcd64bc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae52314f-cf8f-4851-96f5-7ebdbcd64bc3",
    "outputId": "98fc3a7a-8e6a-4dbf-e0de-e0ec04fc0af2"
   },
   "outputs": [],
   "source": [
    "output_layer = baseline_model.output.weight\n",
    "weights_class = output_layer[9]\n",
    "sum_weights = weights_class.sum().item()\n",
    "\n",
    "print(sum_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dac908-9e3d-4b4d-bd64-8edd1473eb30",
   "metadata": {
    "id": "96dac908-9e3d-4b4d-bd64-8edd1473eb30"
   },
   "source": [
    "**Answer**:  -1.802772045135498"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac977192-4a53-4da3-abfc-28aafa4f55d7",
   "metadata": {
    "id": "ac977192-4a53-4da3-abfc-28aafa4f55d7"
   },
   "source": [
    "Set the number of epochs and learning rate to be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8ccfc-9e64-4051-956d-c7df39b19434",
   "metadata": {
    "id": "75b8ccfc-9e64-4051-956d-c7df39b19434"
   },
   "outputs": [],
   "source": [
    "# to do: set the epochs and the learning rate\n",
    "epochs = 50\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b825ce4-0704-4164-9e5e-ad8e70cc6e2a",
   "metadata": {
    "id": "4b825ce4-0704-4164-9e5e-ad8e70cc6e2a"
   },
   "source": [
    "Now, invoke the training function from earlier, to train the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db864674-c3ab-4b06-b29b-17e3bc0fd1cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db864674-c3ab-4b06-b29b-17e3bc0fd1cb",
    "outputId": "6435985b-cbb2-487b-c693-388272bb1541"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    baseline_train_acc,\n",
    "    baseline_train_loss,\n",
    "    baseline_validation_acc,\n",
    "    baseline_validation_loss,\n",
    ") = train_model(\n",
    "    model=baseline_model,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=validation_loader,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ada2c-e04e-47e5-9394-a86a6824e5ac",
   "metadata": {
    "id": "551ada2c-e04e-47e5-9394-a86a6824e5ac"
   },
   "source": [
    "Let's see how did the model perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28731d86-cb6b-41ae-b005-956df77cfb55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28731d86-cb6b-41ae-b005-956df77cfb55",
    "outputId": "d4cb6042-9690-4d2b-f0a6-4881f22ac33f"
   },
   "outputs": [],
   "source": [
    "baseline_test_acc = evaluate_model(model=baseline_model, data_loader=test_loader)\n",
    "\n",
    "print(f\"Baseline model test accuracy: {baseline_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40256549-fb0e-4eb8-b6e8-73953f21911e",
   "metadata": {
    "id": "40256549-fb0e-4eb8-b6e8-73953f21911e"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-22:** What was the validation loss at epoch 40? What is the test accuracy of the `baseline_model`?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549c05a-f9dc-4d1a-a97d-708cc1925a9c",
   "metadata": {
    "id": "5549c05a-f9dc-4d1a-a97d-708cc1925a9c"
   },
   "source": [
    "**Answer**: Validation loss: 1.9569\n",
    "Accuracy: 0.8444"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4306ed02-37ef-4ebe-a3d4-ae7df4f52c83",
   "metadata": {
    "id": "4306ed02-37ef-4ebe-a3d4-ae7df4f52c83"
   },
   "source": [
    "## Image Classifier (challenger/experimental)\n",
    "\n",
    "It has been more than a decade that we know the ReLU activation function significantly improves the performance of a neural network over the logistic/sigmoid function.\n",
    "However, instead of simply believing the literature, we empirically explore that notion in this notebook.\n",
    "\n",
    "Implement an image classifier neural network with the following specifications,\n",
    "\n",
    "* 2 layers with each layer having 500 neurons each\n",
    "* Each hidden layer will use ReLU function as its activation function\n",
    "* Use SGD as the optimization algorithm with learning rate $1 \\times 10^{-3}$\n",
    "\n",
    "Train for 50 epochs with mini-batch size 100. This will serve as our challenger or experimental model.\n",
    "\n",
    "Notice that the only change we introduced was the usage of ReLU activation, all other design choices remain the same. This affords us a more \"apples-to-apples\" comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0cb33-4dcc-47fb-84e5-9c51b5001cc6",
   "metadata": {
    "id": "33c0cb33-4dcc-47fb-84e5-9c51b5001cc6"
   },
   "outputs": [],
   "source": [
    "class ClassifierB(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # to do: define the hidden layers\n",
    "        self.hidden1 = torch.nn.Linear(64, 500)  \n",
    "        self.hidden2 = torch.nn.Linear(500, 500)\n",
    "        self.output = torch.nn.Linear(500, 10)\n",
    "\n",
    "        # to do: define the classification layer\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        # to do: define the forward propagation\n",
    "        x = self.relu(self.hidden1(features))\n",
    "        x = self.relu(self.hidden2(x))\n",
    "        logits = self.output(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2d226-a88f-4f3f-b517-fd36b8306601",
   "metadata": {
    "id": "0be2d226-a88f-4f3f-b517-fd36b8306601"
   },
   "source": [
    "Initialize the experimental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d48ab-d54c-4286-b390-9fe741ac6c78",
   "metadata": {
    "id": "c55d48ab-d54c-4286-b390-9fe741ac6c78"
   },
   "outputs": [],
   "source": [
    "# to do: initialze the experimental model\n",
    "experimental_model = ClassifierB()\n",
    "\n",
    "# to do: switch to GPU for computations\n",
    "device = torch.device(\"cuda\" \n",
    "                      if torch.cuda.is_available() \n",
    "                      else \"cpu\")\n",
    "experimental_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192cb1df-1f8c-49f2-b031-04777eba8dae",
   "metadata": {
    "id": "192cb1df-1f8c-49f2-b031-04777eba8dae"
   },
   "source": [
    "Train the experimental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917cf8f-176b-4546-ae4a-28d4483ad9b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7917cf8f-176b-4546-ae4a-28d4483ad9b2",
    "outputId": "14e8be99-c8b5-455d-f4fd-7c3d8f3a42a3"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    experimental_train_acc,\n",
    "    experimental_train_loss,\n",
    "    experimental_validation_acc,\n",
    "    experimental_validation_loss,\n",
    ") = train_model(\n",
    "    model=experimental_model,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=validation_loader,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e140beb-a18a-4071-b330-6046245fbe54",
   "metadata": {
    "id": "1e140beb-a18a-4071-b330-6046245fbe54"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-23:** What was the training loss and validation loss at epoch 35?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6fe90a-3915-4373-8b20-b489979a26e2",
   "metadata": {
    "id": "9a6fe90a-3915-4373-8b20-b489979a26e2"
   },
   "source": [
    "**Answer**: Training loss: 0.0650\n",
    "Validation loss: 0.0864"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc19bb2c-e388-4ea0-81c0-9e7f9c97e740",
   "metadata": {
    "id": "fc19bb2c-e388-4ea0-81c0-9e7f9c97e740"
   },
   "source": [
    "Evaluate the trained experimental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e2f07-fa6d-4355-94b0-82a5cfec4994",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd9e2f07-fa6d-4355-94b0-82a5cfec4994",
    "outputId": "f377751f-9b09-46e4-85e4-39fcee766f15"
   },
   "outputs": [],
   "source": [
    "experimental_test_acc = evaluate_model(\n",
    "    model=experimental_model, data_loader=test_loader\n",
    ")\n",
    "\n",
    "print(f\"Experimental model test accuracy: {experimental_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84fb71d-a9fe-4b08-ab4a-af377ca9d1bf",
   "metadata": {
    "id": "b84fb71d-a9fe-4b08-ab4a-af377ca9d1bf"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-24:** What is the test accuracy of the experimental model?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457a68a-e280-4390-a210-e9fa1163aac7",
   "metadata": {
    "id": "3457a68a-e280-4390-a210-e9fa1163aac7"
   },
   "source": [
    "**Answer**: 0.9833"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342ff8e-7776-4fbc-b09c-376bb93ca7ff",
   "metadata": {
    "id": "3342ff8e-7776-4fbc-b09c-376bb93ca7ff"
   },
   "source": [
    "## Performance Curves\n",
    "\n",
    "Now, we define plotting functions for the training and validation losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209873aa-ade6-4dea-a9f7-0c5818c41c5f",
   "metadata": {
    "id": "209873aa-ade6-4dea-a9f7-0c5818c41c5f"
   },
   "outputs": [],
   "source": [
    "def plot_training_values(\n",
    "    training_values: List,\n",
    "    validation_values: List,\n",
    "    title: str,\n",
    "    x_label: str,\n",
    "    y_label: str,\n",
    ") -> None:\n",
    "    plt.plot(\n",
    "        np.cumsum(training_values) / np.arange(1, len(training_values) + 1),\n",
    "        label=\"Training\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.cumsum(validation_values) / np.arange(1, len(validation_values) + 1),\n",
    "        label=\"Validation\",\n",
    "    )\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5c216-a94d-4dda-bab0-4bff4829d300",
   "metadata": {
    "id": "0dc5c216-a94d-4dda-bab0-4bff4829d300"
   },
   "source": [
    "Next, we define the function for plotting the loss or accuracy curves to compare the baseline model and the experimental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab7877-d9ad-42f2-aead-f505af2c052e",
   "metadata": {
    "id": "6aab7877-d9ad-42f2-aead-f505af2c052e"
   },
   "outputs": [],
   "source": [
    "def plot_model_values(\n",
    "    baseline_values: List,\n",
    "    experimental_values: List,\n",
    "    title: str,\n",
    "    x_label: str,\n",
    "    y_label: str,\n",
    ") -> None:\n",
    "    plt.plot(\n",
    "        np.cumsum(baseline_values) / np.arange(1, len(baseline_values) + 1),\n",
    "        label=\"Baseline\",\n",
    "    )  # cumulative moving average\n",
    "    plt.plot(\n",
    "        np.cumsum(experimental_values) / np.arange(1, len(experimental_values) + 1),\n",
    "        label=\"Experimental\",\n",
    "    )\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c8388-dd8b-4c54-86d3-ea6a0d16fd38",
   "metadata": {
    "id": "116c8388-dd8b-4c54-86d3-ea6a0d16fd38"
   },
   "source": [
    "Then, we plot the training and validation loss curves for the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff9b88-d231-456a-bee6-794fe859ed9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "bbff9b88-d231-456a-bee6-794fe859ed9c",
    "outputId": "eef87fb3-c6c8-4e6b-d42b-d57faf75a911"
   },
   "outputs": [],
   "source": [
    "plot_training_values(\n",
    "    training_values=baseline_train_loss,\n",
    "    validation_values=baseline_validation_loss,\n",
    "    title=\"Baseline Loss Curves\",\n",
    "    x_label=\"Step\",\n",
    "    y_label=\"Loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06d6de-5037-4841-b831-9ff97467b46b",
   "metadata": {
    "id": "6c06d6de-5037-4841-b831-9ff97467b46b"
   },
   "source": [
    "Then, we plot the training and validation accuracy curves for the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3f602-577e-4fd1-bab0-cc07a08fc621",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "b7d3f602-577e-4fd1-bab0-cc07a08fc621",
    "outputId": "845fbc36-d8ec-41ca-ced9-3ffd6accddca"
   },
   "outputs": [],
   "source": [
    "plot_training_values(\n",
    "    training_values=baseline_train_acc,\n",
    "    validation_values=baseline_validation_acc,\n",
    "    title=\"Baseline Accuracy Curves\",\n",
    "    x_label=\"Step\",\n",
    "    y_label=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d016fce-3de3-47bb-b5c6-bafd97c63eaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "4d016fce-3de3-47bb-b5c6-bafd97c63eaa",
    "outputId": "edfa31ce-558c-4782-c7ca-d6728589574d"
   },
   "outputs": [],
   "source": [
    "plot_training_values(\n",
    "    training_values=experimental_train_loss,\n",
    "    validation_values=experimental_validation_loss,\n",
    "    title=\"Experimental Loss Curves\",\n",
    "    x_label=\"Step\",\n",
    "    y_label=\"Loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3a10e-14ee-4515-ae94-fbcb94804914",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "a0c3a10e-14ee-4515-ae94-fbcb94804914",
    "outputId": "c611c75b-d927-4d16-d82f-4fa784e89e30"
   },
   "outputs": [],
   "source": [
    "plot_training_values(\n",
    "    training_values=experimental_train_acc,\n",
    "    validation_values=experimental_validation_acc,\n",
    "    title=\"Experimental Accuracy Curves\",\n",
    "    x_label=\"Step\",\n",
    "    y_label=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4eca5-e07c-49cb-849d-c9ea387e92d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "73e4eca5-e07c-49cb-849d-c9ea387e92d6",
    "outputId": "4165766d-916c-4ddc-cd13-cb54805de8a1"
   },
   "outputs": [],
   "source": [
    "plot_model_values(\n",
    "    baseline_train_loss,\n",
    "    experimental_train_loss,\n",
    "    title=\"Training Loss (Baseline vs Experimental)\",\n",
    "    x_label=\"Steps\",\n",
    "    y_label=\"Loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054b719-b6aa-4277-ab4f-4af11127f323",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "a054b719-b6aa-4277-ab4f-4af11127f323",
    "outputId": "c3bde633-0f54-4f8a-e8ea-65982920af29"
   },
   "outputs": [],
   "source": [
    "plot_model_values(\n",
    "    baseline_validation_loss,\n",
    "    experimental_validation_loss,\n",
    "    title=\"Validation Loss (Baseline vs Experimental)\",\n",
    "    x_label=\"Steps\",\n",
    "    y_label=\"Loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d6afc-1502-444e-9044-49426b6a7cd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "813d6afc-1502-444e-9044-49426b6a7cd1",
    "outputId": "84305b96-f0dd-49cf-ec93-aeadcb843816"
   },
   "outputs": [],
   "source": [
    "plot_model_values(\n",
    "    baseline_train_acc,\n",
    "    experimental_train_acc,\n",
    "    title=\"Training Accuracy (Baseline vs Experimental)\",\n",
    "    x_label=\"Steps\",\n",
    "    y_label=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8ff95-b64b-4986-bb43-a748eb580042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "c7a8ff95-b64b-4986-bb43-a748eb580042",
    "outputId": "467093bc-59ac-449d-c697-a3e4c67c1174"
   },
   "outputs": [],
   "source": [
    "plot_model_values(\n",
    "    baseline_validation_acc,\n",
    "    experimental_validation_acc,\n",
    "    title=\"Validation Accuracy (Baseline vs Experimental)\",\n",
    "    x_label=\"Steps\",\n",
    "    y_label=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e2b9b-9336-4967-8055-ffdffce1a297",
   "metadata": {
    "id": "8f5e2b9b-9336-4967-8055-ffdffce1a297"
   },
   "source": [
    "## Ablation on Experimental Model\n",
    "\n",
    "Now, let's play with our experimental model, and try to see if we could further improve its performance.\n",
    "\n",
    "Implement an image classifier neural network with the following specifications,\n",
    "\n",
    "* 2 layers with each layer having 500 neurons each\n",
    "* Each hidden layer will use ReLU function as its activation function\n",
    "* Use SGD as the optimization algorithm with the following learning rates\n",
    "  * $1 \\times 10^{-1}$\n",
    "  * $1 \\times 10^{-2}$\n",
    "  * $1 \\times 10^{-3}$\n",
    "  * $1 \\times 10^{-4}$\n",
    "\n",
    "Train for 50 epochs with mini-batch size 100. This will serve as our challenger or experimental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3aa906-dc14-409c-aa15-cd0ddba96c30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c3aa906-dc14-409c-aa15-cd0ddba96c30",
    "outputId": "52fa9392-543b-4b56-aebe-98caaa7a04bf"
   },
   "outputs": [],
   "source": [
    "# to do: define the list of learning rates\n",
    "learning_rates = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    # to do: initialize an experimental model for the current learning rate\n",
    "    experimental_model = ClassifierB()\n",
    "\n",
    "    # to do: switch to GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    experimental_model.to(device)\n",
    "\n",
    "    print(f\"Training model with learning rate = {learning_rate}\")\n",
    "\n",
    "    # to do: run the model training for the given learning rate\n",
    "    (\n",
    "        experimental_train_acc,\n",
    "        experimental_train_loss,\n",
    "        experimental_validation_acc,\n",
    "        experimental_validation_loss,\n",
    "    ) = train_model(\n",
    "        model=experimental_model,\n",
    "        train_loader=train_loader,\n",
    "        validation_loader=validation_loader,\n",
    "        epochs=50,\n",
    "        learning_rate=learning_rate,\n",
    "    )\n",
    "\n",
    "    # to do: evaluate the trained model\n",
    "    experimental_test_acc = evaluate_model(experimental_model, test_loader)\n",
    "    print(f\"Test accuracy: {experimental_test_acc:.4f}\")\n",
    "\n",
    "    # store the results for later retrieval\n",
    "    results[f\"lr-{learning_rate}\"] = dict(\n",
    "        train_acc=experimental_train_acc,\n",
    "        train_loss=experimental_train_loss,\n",
    "        validation_loss=experimental_validation_loss,\n",
    "        validation_acc=experimental_validation_acc,\n",
    "        test_accuracy=experimental_test_acc\n",
    "    )\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee8093c-3ac0-44ce-81c6-0eb0d50d3f84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eee8093c-3ac0-44ce-81c6-0eb0d50d3f84",
    "outputId": "23dba6d8-f43b-45a3-af54-b2b4161b8033"
   },
   "outputs": [],
   "source": [
    "for learning_rate in learning_rates:\n",
    "    plot_training_values(\n",
    "        training_values=results[f\"lr-{learning_rate}\"][\"train_acc\"],\n",
    "        validation_values=results[f\"lr-{learning_rate}\"][\"validation_acc\"],\n",
    "        title=f\"Accuracy Curves (lr={learning_rate})\",\n",
    "        x_label=\"Step\",\n",
    "        y_label=\"Accuracy\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc234798-247f-4b99-a2b6-d80c8028aed5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dc234798-247f-4b99-a2b6-d80c8028aed5",
    "outputId": "f795379d-48c4-429f-f9e0-08d379ecc2af"
   },
   "outputs": [],
   "source": [
    "for learning_rate in learning_rates:\n",
    "    plot_training_values(\n",
    "        training_values=results[f\"lr-{learning_rate}\"][\"train_loss\"],\n",
    "        validation_values=results[f\"lr-{learning_rate}\"][\"validation_loss\"],\n",
    "        title=f\"Loss Curves (lr={learning_rate})\",\n",
    "        x_label=\"Step\",\n",
    "        y_label=\"Loss\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MCTGTF2sR-6i",
   "metadata": {
    "id": "MCTGTF2sR-6i"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-25:** What was the best test accuracy across the 4 learning rates used for the model? What was the learning rate used?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98LPjJD7SF1A",
   "metadata": {
    "id": "98LPjJD7SF1A"
   },
   "source": [
    "**Answer**: accuracy: 0.9750\n",
    "learning rate for A: 0.1\n",
    "learning rate for b: 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ulWtUdTECH",
   "metadata": {
    "id": "f6ulWtUdTECH"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-26:** Based on the loss curves, what can you say about the model when it was trained with a learning rate of 0.0001?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iEEhHv7NTRkt",
   "metadata": {
    "id": "iEEhHv7NTRkt"
   },
   "source": [
    "**Answers**: low learning rate because it's below 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0605083-0e06-4d1d-b949-08a9b3f3ac85",
   "metadata": {},
   "source": [
    "### <center>fin</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5eee9-8cfd-44b9-9194-f6ce226c33d5",
   "metadata": {},
   "source": [
    "\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->\n",
    "<sup>written by Abien Fred Agarap</sup> <br>\n",
    "<sup>for comments, corrections, suggestions, please email:</sup><sup> abienfred.agarap@gmail.com</sup><br>\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
