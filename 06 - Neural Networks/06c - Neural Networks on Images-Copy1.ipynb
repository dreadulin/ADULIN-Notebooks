{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5a6deb-3b06-4b1a-8084-eaec28995882",
   "metadata": {
    "id": "2a5a6deb-3b06-4b1a-8084-eaec28995882"
   },
   "source": [
    "# Neural Networks on Image Dataset\n",
    "\n",
    "In this notebook, we tackle a simple image classification dataset from sklearn: the digits dataset (handwritten digits images). For this exercise, we need the `torchvision` library. To install it, simply use the following installation command,\n",
    "\n",
    "```shell\n",
    "pip install torchvision\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05402ef6-38ca-47d4-8275-e76360f17f07",
   "metadata": {
    "id": "05402ef6-38ca-47d4-8275-e76360f17f07"
   },
   "source": [
    "## Instructions for All Labs\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* Some markdown cells contain questions.\n",
    "  * For questions <span style=\"color:red;\">colored in red</span>, you must submit your answers in the corresponding Assignment in the course page. Make sure that you enter your responses in the item with the matching question code. Answers that do not follow the prescribed format will automatically be marked wrong by the checker.\n",
    "  * For questions <span style=\"color:green;\">colored in green</span>, you don't have to submit your answers, but you must think about these questions as they will help enrich your understanding of the concepts covered in the labs.\n",
    "* You are expected to search how to some functions work on the Internet or via the docs.\n",
    "* You may add new cells for \"scrap work\".\n",
    "* The notebooks will undergo a \"Restart and Run All\" command, so make sure that your code is working properly.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3c645b-8dae-4d3d-b3e5-5fbcfde98fbe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b3c645b-8dae-4d3d-b3e5-5fbcfde98fbe",
    "outputId": "f7fe7a29-c750-4ae2-ebfd-efc05408c3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns  # pip install seaborn\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbea4db3-1e53-4aa9-8be9-ed2caa1b1e8a",
   "metadata": {
    "id": "dbea4db3-1e53-4aa9-8be9-ed2caa1b1e8a"
   },
   "source": [
    "Set the seed for PRNG and determinism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a799b3ae-ab56-470d-8605-b04c1e2afb03",
   "metadata": {
    "id": "a799b3ae-ab56-470d-8605-b04c1e2afb03"
   },
   "outputs": [],
   "source": [
    "seed = 73\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4918d82-f392-4361-8b62-45a05df7c800",
   "metadata": {
    "id": "a4918d82-f392-4361-8b62-45a05df7c800"
   },
   "source": [
    "Define the function for plotting a given set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02bd5d76-7497-4b10-9663-4c286b6c02b2",
   "metadata": {
    "id": "02bd5d76-7497-4b10-9663-4c286b6c02b2"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "def show(images: List) -> None:\n",
    "    _, axs = plt.subplots(ncols=len(images), squeeze=False)\n",
    "    for index, image in enumerate(images):\n",
    "        image = image.detach()\n",
    "        axs[0, index].imshow(np.asarray(image), cmap=\"gray\")\n",
    "        axs[0, index].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8831a50-b6de-4cdc-a643-8161d7874082",
   "metadata": {
    "id": "d8831a50-b6de-4cdc-a643-8161d7874082"
   },
   "source": [
    "Load the digits dataset which consists of the features $X$ and labels $y$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccba4258-2a89-4195-95a9-3e10ca5dabf8",
   "metadata": {
    "id": "ccba4258-2a89-4195-95a9-3e10ca5dabf8"
   },
   "outputs": [],
   "source": [
    "images, labels = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c6768e-5078-4618-9d6e-d7213117d09c",
   "metadata": {
    "id": "b9c6768e-5078-4618-9d6e-d7213117d09c"
   },
   "source": [
    "Check the shape of the images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e69f1d-bf7b-461a-bff0-c4e7810cac1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08e69f1d-bf7b-461a-bff0-c4e7810cac1a",
    "outputId": "7e2963dd-d8c7-4293-bb89-9a11ec4f57ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea3e3f-0df3-46a1-8672-1d411a88cda9",
   "metadata": {
    "id": "3fea3e3f-0df3-46a1-8672-1d411a88cda9"
   },
   "source": [
    "Check samples of the images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20040e1e-b21b-462e-91f2-ffe981546d09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20040e1e-b21b-462e-91f2-ffe981546d09",
    "outputId": "88b151dc-fc65-46bd-d831-7e600c6a6379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      "  15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "   0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "   0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
      " [ 0.  0.  0. 12. 13.  5.  0.  0.  0.  0.  0. 11. 16.  9.  0.  0.  0.  0.\n",
      "   3. 15. 16.  6.  0.  0.  0.  7. 15. 16. 16.  2.  0.  0.  0.  0.  1. 16.\n",
      "  16.  3.  0.  0.  0.  0.  1. 16. 16.  6.  0.  0.  0.  0.  1. 16. 16.  6.\n",
      "   0.  0.  0.  0.  0. 11. 16. 10.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(images[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f80ce7e-30cb-454b-85dd-3944e9dced99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f80ce7e-30cb-454b-85dd-3944e9dced99",
    "outputId": "fbaca842-fd3e-4599-85d1-445b854923b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387f32e-b777-4f00-a60d-153d3f3b5c32",
   "metadata": {
    "id": "8387f32e-b777-4f00-a60d-153d3f3b5c32"
   },
   "source": [
    "From here, we can see that there are 1,797 instances of images and labels. However, we can see that each \"image\" has 1x64 vectors.\n",
    "\n",
    "Meanwhile, an image is supposed to have a width x length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e4a9f6a-a8b7-4dcb-9545-50709c84b906",
   "metadata": {
    "id": "3e4a9f6a-a8b7-4dcb-9545-50709c84b906"
   },
   "outputs": [],
   "source": [
    "# to do: reshape the `images` tensor to be of `num_instances x width x length` shape\n",
    "images = images.reshape(-1,8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e123e8e9-9c14-4a94-ada7-78467268ece2",
   "metadata": {
    "id": "e123e8e9-9c14-4a94-ada7-78467268ece2"
   },
   "source": [
    "Retrieve the only first 5 images for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b212e3-9c93-4e48-9990-a95820e6f7c1",
   "metadata": {
    "id": "51b212e3-9c93-4e48-9990-a95820e6f7c1"
   },
   "outputs": [],
   "source": [
    "# to do: retrieve the first 5 images\n",
    "tensor = torch.tensor(images[:5]).unsqueeze(1).reshape(5,8,8)\n",
    "image_grid = torchvision.utils.make_grid(tensor,nrow=5,pad_value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6dc487-fe82-4c56-a588-d8e6f4db8826",
   "metadata": {
    "id": "6f6dc487-fe82-4c56-a588-d8e6f4db8826"
   },
   "source": [
    "Check that we got the first 5 items and that the images have been properly reshaped. It should have a shape of 5x8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d30b166b-09cb-4a77-a660-f748023b78a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d30b166b-09cb-4a77-a660-f748023b78a8",
    "outputId": "fdddfba6-48ee-44c7-8df0-c5a9447dbc5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_grid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b14b542-a5fe-461d-a7fc-6dc7646284c2",
   "metadata": {
    "id": "1b14b542-a5fe-461d-a7fc-6dc7646284c2"
   },
   "source": [
    "Each image having a shape of 8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34db90a7-27d7-42a5-be14-d0c14eaf5e5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34db90a7-27d7-42a5-be14-d0c14eaf5e5b",
    "outputId": "2043ca0e-ccb7-48fb-be9b-a4dc0fe1021d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_grid[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329fac0-887e-4486-b52e-e1d658baf2ce",
   "metadata": {
    "id": "2329fac0-887e-4486-b52e-e1d658baf2ce"
   },
   "source": [
    "Plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2118f19-7427-4f09-a586-a3c586874877",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "e2118f19-7427-4f09-a586-a3c586874877",
    "outputId": "42dbec55-efa7-41bd-c644-65e54c772f1d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(image_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb040b-cd65-4864-be8b-66a7f10e8df2",
   "metadata": {
    "id": "67bb040b-cd65-4864-be8b-66a7f10e8df2"
   },
   "source": [
    "Confirm the labels of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dd37399-db92-43ed-bf08-c0ace0fa2873",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dd37399-db92-43ed-bf08-c0ace0fa2873",
    "outputId": "5f52faa0-02a5-4356-d4c1-65e3f86152e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# to do: print the labels\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa522d7-9ce8-4d7b-889f-7f3427020f4f",
   "metadata": {
    "id": "6aa522d7-9ce8-4d7b-889f-7f3427020f4f"
   },
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "We split the images and labels to training/validation/test sets. The splitting is as follows,\n",
    "\n",
    "* Training: 80%\n",
    "* Test: 20%\n",
    "\n",
    "Then we get the 20% of the training set as the validation set, leaving us with the following,\n",
    "\n",
    "* Training: 64%\n",
    "* Validation: 16%\n",
    "* Test: 20%\n",
    "\n",
    "Recall that we reshaped our images to be of $num\\_instances \\times width \\times length$ shape.\n",
    "\n",
    "So, we have to reshape it back to $num\\_instances \\times dimensions$ before splitting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa91b85e-5f19-4769-9e82-95f0c4fbe933",
   "metadata": {
    "id": "aa91b85e-5f19-4769-9e82-95f0c4fbe933"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images = images.reshape(images.shape[0], -1)\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=2e-1, stratify=labels, shuffle=True, random_state=seed\n",
    ")\n",
    "\n",
    "train_features, validation_features, train_labels, validation_labels = train_test_split(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    test_size=2e-1,\n",
    "    stratify=train_labels,\n",
    "    shuffle=True,\n",
    "    random_state=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb333ce-5d9d-4021-a377-e3bb25962b99",
   "metadata": {
    "id": "4cb333ce-5d9d-4021-a377-e3bb25962b99"
   },
   "source": [
    "Confirm the dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26b69ef3-a453-4458-aecd-4f55281e3fdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26b69ef3-a453-4458-aecd-4f55281e3fdc",
    "outputId": "2af105af-8a19-498f-ca7e-3083509a6850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "\tTraining: 1149, Validation: 288, Test: 360\n"
     ]
    }
   ],
   "source": [
    "# to do: print the dataset sizes\n",
    "print(f\"Dataset sizes:\")\n",
    "print(\n",
    "    #we get the actual count of elements in our train featurses, validation features and in our test set\n",
    "    f\"\\tTraining: {len(train_features)}, Validation: {len(validation_features)}, Test: {len(test_features)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c0b8a-f279-4cdb-aef6-73bc9af81595",
   "metadata": {
    "id": "201c0b8a-f279-4cdb-aef6-73bc9af81595"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-19:** How many instances are there in the training, validation, and test sets respectively?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0113a54-3502-402a-98ec-4f42af80376c",
   "metadata": {
    "id": "201c0b8a-f279-4cdb-aef6-73bc9af81595"
   },
   "source": [
    "**Answer**: Training = 1149\n",
    "Validation = 288\n",
    "Test set = 360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c657da0-3b65-4e5a-9b58-2a0201c67c72",
   "metadata": {
    "id": "1c657da0-3b65-4e5a-9b58-2a0201c67c72"
   },
   "source": [
    "After splitting the dataset into training/validation/test sets, we can now pack them into PyTorch tensor objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40f189ab-c806-478d-8e96-2a1aa4bb769a",
   "metadata": {
    "id": "40f189ab-c806-478d-8e96-2a1aa4bb769a"
   },
   "outputs": [],
   "source": [
    "train_features = torch.from_numpy(train_features).float()\n",
    "train_labels = torch.from_numpy(train_labels)\n",
    "\n",
    "# to do: pack the validation and test data into torch tensors.\n",
    "validation_features = torch.tensor(validation_features, dtype=torch.float32)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "test_features = torch.tensor(test_features, dtype=torch.float32)\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e73e2-8e4c-4c8c-af2b-494a5acdea6f",
   "metadata": {
    "id": "878e73e2-8e4c-4c8c-af2b-494a5acdea6f"
   },
   "source": [
    "For these data to be ingestible for our model, we have to pack them into a [TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset) objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d27581a8-9b3c-437b-ad6e-c00510ead45c",
   "metadata": {
    "id": "d27581a8-9b3c-437b-ad6e-c00510ead45c"
   },
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "\n",
    "# to do: pack the validation and test features and labels into a TensorDataset\n",
    "validation_dataset = torch.utils.data.TensorDataset(validation_features, validation_labels)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed870926-8d0f-4cd6-beaa-2df33df8119d",
   "metadata": {
    "id": "ed870926-8d0f-4cd6-beaa-2df33df8119d"
   },
   "source": [
    "To automate the batching of the datasets during training, we pack them into [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5764a1c4-1595-483b-bd9c-9b7b8675f826",
   "metadata": {
    "id": "5764a1c4-1595-483b-bd9c-9b7b8675f826"
   },
   "outputs": [],
   "source": [
    "# define the batch size\n",
    "batch_size = 100\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "# to do: pack the datasets into data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=multiprocessing.cpu_count(),\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=len(validation_dataset),\n",
    "    num_workers=multiprocessing.cpu_count(),\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=len(test_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec46a347-b4ab-448e-b3e7-d395af3059cd",
   "metadata": {
    "id": "ec46a347-b4ab-448e-b3e7-d395af3059cd"
   },
   "source": [
    "## Image Classifier (baseline)\n",
    "\n",
    "Implement an image classifier neural network with the following specifications,\n",
    "\n",
    "* 2 layers with each layer having 500 neurons each\n",
    "* Each hidden layer will use logistic/sigmoid function as its activation function\n",
    "* Use SGD as the optimization algorithm with learning rate $1 \\times 10^{-3}$\n",
    "\n",
    "Train for 50 epochs with mini-batch size 100. This will serve as our baseline model, which uses logistic/sigmoid function to learn the nonlinear relationships in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a81b523-01dd-4c1d-8722-85ddd7b82861",
   "metadata": {
    "id": "7a81b523-01dd-4c1d-8722-85ddd7b82861"
   },
   "outputs": [],
   "source": [
    "class ClassifierA(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # to do: define the hidden layers\n",
    "        self.hidden1 = torch.nn.Linear(64, 500)\n",
    "        self.hidden2 = torch.nn.Linear(500, 500)\n",
    "        self.output = torch.nn.Linear(500, 10)\n",
    "        \n",
    "        # to do: define the classification layer\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        # to do: define the forward pass function\n",
    "        x = self.activation(self.hidden1(features))\n",
    "        x = self.sigmoid(self.hidden2(x))\n",
    "        logits = self.output(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e7ec6-3290-418e-9797-240e657d6426",
   "metadata": {
    "id": "056e7ec6-3290-418e-9797-240e657d6426"
   },
   "source": [
    "For convenience, we define a training function for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ef131a1-b8fc-4314-a986-81ea6cb7e60e",
   "metadata": {
    "id": "3ef131a1-b8fc-4314-a986-81ea6cb7e60e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    validation_loader: torch.utils.data.DataLoader,\n",
    "    epochs: int = 50,\n",
    "    learning_rate: float = 1e-2,\n",
    "    display_interval: int = 5\n",
    ") -> Tuple[List, List, List, List]:\n",
    "\n",
    "    # to do:\n",
    "    # set the learning rate, pass the model parameters to be optimized\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),lr=learning_rate\n",
    "    )\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_acc = list()\n",
    "    train_loss = list()\n",
    "    validation_acc = list()\n",
    "    validation_loss = list()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_loss = list()\n",
    "        epoch_acc = list()\n",
    "        \n",
    "        for features_batch, labels_batch in train_loader:\n",
    "            # to do: zero out the gradients to prevent gradient accumulation\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # to do: switch the features to GPU\n",
    "            features_batch = features_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device).long()\n",
    "\n",
    "            # to do: compute model predictions\n",
    "            model_predictions = model(features_batch)\n",
    "\n",
    "            # to do: compute the loss\n",
    "            loss = criterion(model_predictions, labels_batch)\n",
    "\n",
    "            # to do: compute accuracy of predictions in [0, 1] range\n",
    "            predictions = torch.argmax(model_predictions, dim=1)\n",
    "            acc = (predictions == labels_batch).float().mean().item()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            train_acc.append(acc)\n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_acc.append(acc)\n",
    "\n",
    "            # to do: run backprop\n",
    "            loss.backward()\n",
    "\n",
    "            # to do: optimize the weights based on backpropagated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # to do: run model in inference mode\n",
    "                model.eval()\n",
    "                for features_batch, labels_batch in validation_loader:\n",
    "                    # to do: switch the features and labels to GPU\n",
    "                    features_batch = features_batch.to(device)\n",
    "                    labels_batch = labels_batch.to(device).long()\n",
    "\n",
    "                    # to do: compute the model predictions\n",
    "                    model_predictions = model(features_batch)\n",
    "\n",
    "                    # to do: compute the loss\n",
    "                    loss=criterion(model_predictions, labels_batch)\n",
    "\n",
    "                    # to do: compute the model predictions accuracy in [0, 1] range\n",
    "                    predictions = torch.argmax(model_predictions, dim=1)\n",
    "                    acc = (predictions == labels_batch).float().mean().item()\n",
    "\n",
    "                    validation_loss.append(loss.item())\n",
    "                    validation_acc.append(acc)\n",
    "\n",
    "            # to do: enable training mode again\n",
    "            model.train()\n",
    "\n",
    "        if (epoch + 1) % display_interval == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "            print(\n",
    "                f\"\\tTraining Loss:  {np.mean(epoch_loss):.4f}, Training Acc: {np.mean(epoch_acc):.4f}\"\n",
    "            )\n",
    "            print(f\"\\tValidation Loss: {loss.item():.4f}, Validation Acc: {acc:.4f}\")\n",
    "\n",
    "    return train_acc, train_loss, validation_acc, validation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f9c19e-5354-407d-8c5f-b2cc0d87ca95",
   "metadata": {
    "id": "20f9c19e-5354-407d-8c5f-b2cc0d87ca95"
   },
   "source": [
    "We also prepare an evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e59991d4-38b9-456f-a804-7d6d70acf410",
   "metadata": {
    "id": "e59991d4-38b9-456f-a804-7d6d70acf410"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: torch.nn.Module, data_loader: torch.utils.data.DataLoader\n",
    ") -> float:\n",
    "    # to do: disable gradient computation\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # to do: set model for pure eval\n",
    "        model.eval()\n",
    "\n",
    "        # to do: switch to CPU for computations\n",
    "        device = torch.device(\"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        for features_batch, labels_batch in data_loader:\n",
    "            # to do: compute the model predictions\n",
    "            features_batch = features_batch.to(device)\n",
    "            labels_batch = labels_batch.to(device).long()\n",
    "\n",
    "            model_predictions = model(features_batch)\n",
    "            predictions = torch.argmax(model_predictions,dim=1)\n",
    "\n",
    "            # to do: compute the accuracy of the predictions in [0, 1]-range\n",
    "            correct_predicitons = 0\n",
    "            samples = 0 \n",
    "\n",
    "            correct_predicitons += (predictions == labels_batch).sum().item()\n",
    "            samples += labels_batch.size(0)\n",
    "\n",
    "    acc = (correct_predicitons/samples)\n",
    "    return acc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740b910-9228-42a8-a0d4-ef9579b67da3",
   "metadata": {
    "id": "3740b910-9228-42a8-a0d4-ef9579b67da3"
   },
   "source": [
    "Initialize the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcb7239a-b632-4088-896f-112e460efaef",
   "metadata": {
    "id": "bcb7239a-b632-4088-896f-112e460efaef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierA(\n",
       "  (hidden1): Linear(in_features=64, out_features=500, bias=True)\n",
       "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (output): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the model\n",
    "baseline_model = ClassifierA()\n",
    "\n",
    "# switch to GPU for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "baseline_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb3708-26f0-4296-bcb0-c442a8669461",
   "metadata": {
    "id": "84eb3708-26f0-4296-bcb0-c442a8669461"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-20:** What is the summation of the initial weight parameters for class 0 in the `baseline_model`?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10438ed5-34a2-4e97-ae21-2401a69b96b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10438ed5-34a2-4e97-ae21-2401a69b96b6",
    "outputId": "630df493-cd36-4140-c15a-7ef1510cfb33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11486731469631195\n"
     ]
    }
   ],
   "source": [
    "output_layer = baseline_model.output.weight\n",
    "weights_class = output_layer[0]\n",
    "sum_weights = weights_class.sum().item()\n",
    "\n",
    "print(sum_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb61e40e-2e82-4659-b44d-5fd6695be2bc",
   "metadata": {
    "id": "cb61e40e-2e82-4659-b44d-5fd6695be2bc"
   },
   "source": [
    "**Answer**: -0.11486731469631195"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff46f5-c0da-4992-be93-36f69974d65e",
   "metadata": {
    "id": "81ff46f5-c0da-4992-be93-36f69974d65e"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-21:** What is the summation of the initial weight parameters for class 9 in the `baseline_model`?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae52314f-cf8f-4851-96f5-7ebdbcd64bc3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae52314f-cf8f-4851-96f5-7ebdbcd64bc3",
    "outputId": "98fc3a7a-8e6a-4dbf-e0de-e0ec04fc0af2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.802772045135498\n"
     ]
    }
   ],
   "source": [
    "output_layer = baseline_model.output.weight\n",
    "weights_class = output_layer[9]\n",
    "sum_weights = weights_class.sum().item()\n",
    "\n",
    "print(sum_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dac908-9e3d-4b4d-bd64-8edd1473eb30",
   "metadata": {
    "id": "96dac908-9e3d-4b4d-bd64-8edd1473eb30"
   },
   "source": [
    "**Answer**:  -1.802772045135498"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac977192-4a53-4da3-abfc-28aafa4f55d7",
   "metadata": {
    "id": "ac977192-4a53-4da3-abfc-28aafa4f55d7"
   },
   "source": [
    "Set the number of epochs and learning rate to be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75b8ccfc-9e64-4051-956d-c7df39b19434",
   "metadata": {
    "id": "75b8ccfc-9e64-4051-956d-c7df39b19434"
   },
   "outputs": [],
   "source": [
    "# to do: set the epochs and the learning rate\n",
    "epochs = 50\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b825ce4-0704-4164-9e5e-ad8e70cc6e2a",
   "metadata": {
    "id": "4b825ce4-0704-4164-9e5e-ad8e70cc6e2a"
   },
   "source": [
    "Now, invoke the training function from earlier, to train the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db864674-c3ab-4b06-b29b-17e3bc0fd1cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db864674-c3ab-4b06-b29b-17e3bc0fd1cb",
    "outputId": "6435985b-cbb2-487b-c693-388272bb1541"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ClassifierA' object has no attribute 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m (\n\u001b[0;32m      2\u001b[0m     baseline_train_acc,\n\u001b[0;32m      3\u001b[0m     baseline_train_loss,\n\u001b[0;32m      4\u001b[0m     baseline_validation_acc,\n\u001b[0;32m      5\u001b[0m     baseline_validation_loss,\n\u001b[1;32m----> 6\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 36\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, validation_loader, epochs, learning_rate, display_interval)\u001b[0m\n\u001b[0;32m     33\u001b[0m labels_batch \u001b[38;5;241m=\u001b[39m labels_batch\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# to do: compute model predictions\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m model_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# to do: compute the loss\u001b[39;00m\n\u001b[0;32m     39\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(model_predictions, labels_batch)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m, in \u001b[0;36mClassifierA.forward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# to do: define the forward pass function\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden1(features))\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden2(x))\n\u001b[0;32m     16\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(x)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1930\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ClassifierA' object has no attribute 'activation'"
     ]
    }
   ],
   "source": [
    "(\n",
    "    baseline_train_acc,\n",
    "    baseline_train_loss,\n",
    "    baseline_validation_acc,\n",
    "    baseline_validation_loss,\n",
    ") = train_model(\n",
    "    model=baseline_model,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=validation_loader,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ada2c-e04e-47e5-9394-a86a6824e5ac",
   "metadata": {
    "id": "551ada2c-e04e-47e5-9394-a86a6824e5ac"
   },
   "source": [
    "Let's see how did the model perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28731d86-cb6b-41ae-b005-956df77cfb55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28731d86-cb6b-41ae-b005-956df77cfb55",
    "outputId": "d4cb6042-9690-4d2b-f0a6-4881f22ac33f"
   },
   "outputs": [],
   "source": [
    "baseline_test_acc = evaluate_model(model=baseline_model, data_loader=test_loader)\n",
    "\n",
    "print(f\"Baseline model test accuracy: {baseline_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40256549-fb0e-4eb8-b6e8-73953f21911e",
   "metadata": {
    "id": "40256549-fb0e-4eb8-b6e8-73953f21911e"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-22:** What was the validation loss at epoch 40? What is the test accuracy of the `baseline_model`?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549c05a-f9dc-4d1a-a97d-708cc1925a9c",
   "metadata": {
    "id": "5549c05a-f9dc-4d1a-a97d-708cc1925a9c"
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4306ed02-37ef-4ebe-a3d4-ae7df4f52c83",
   "metadata": {
    "id": "4306ed02-37ef-4ebe-a3d4-ae7df4f52c83"
   },
   "source": [
    "## Image Classifier (challenger/experimental)\n",
    "\n",
    "It has been more than a decade that we know the ReLU activation function significantly improves the performance of a neural network over the logistic/sigmoid function.\n",
    "However, instead of simply believing the literature, we empirically explore that notion in this notebook.\n",
    "\n",
    "Implement an image classifier neural network with the following specifications,\n",
    "\n",
    "* 2 layers with each layer having 500 neurons each\n",
    "* Each hidden layer will use ReLU function as its activation function\n",
    "* Use SGD as the optimization algorithm with learning rate $1 \\times 10^{-3}$\n",
    "\n",
    "Train for 50 epochs with mini-batch size 100. This will serve as our challenger or experimental model.\n",
    "\n",
    "Notice that the only change we introduced was the usage of ReLU activation, all other design choices remain the same. This affords us a more \"apples-to-apples\" comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0cb33-4dcc-47fb-84e5-9c51b5001cc6",
   "metadata": {
    "id": "33c0cb33-4dcc-47fb-84e5-9c51b5001cc6"
   },
   "outputs": [],
   "source": [
    "class ClassifierB(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # to do: define the hidden layers\n",
    "        ...\n",
    "\n",
    "        # to do: define the classification layer\n",
    "        ...\n",
    "\n",
    "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
    "        # to do: define the forward propagation\n",
    "        ...\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2d226-a88f-4f3f-b517-fd36b8306601",
   "metadata": {
    "id": "0be2d226-a88f-4f3f-b517-fd36b8306601"
   },
   "source": [
    "Initialize the experimental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d48ab-d54c-4286-b390-9fe741ac6c78",
   "metadata": {
    "id": "c55d48ab-d54c-4286-b390-9fe741ac6c78"
   },
   "outputs": [],
   "source": [
    "# to do: initialze the experimental model\n",
    "...\n",
    "\n",
    "# to do: switch to GPU for computations\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192cb1df-1f8c-49f2-b031-04777eba8dae",
   "metadata": {
    "id": "192cb1df-1f8c-49f2-b031-04777eba8dae"
   },
   "source": [
    "Train the experimental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917cf8f-176b-4546-ae4a-28d4483ad9b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7917cf8f-176b-4546-ae4a-28d4483ad9b2",
    "outputId": "14e8be99-c8b5-455d-f4fd-7c3d8f3a42a3"
   },
   "outputs": [],
   "source": [
    "(\n",
    "    experimental_train_acc,\n",
    "    experimental_train_loss,\n",
    "    experimental_validation_acc,\n",
    "    experimental_validation_loss,\n",
    ") = train_model(\n",
    "    model=experimental_model,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=validation_loader,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e140beb-a18a-4071-b330-6046245fbe54",
   "metadata": {
    "id": "1e140beb-a18a-4071-b330-6046245fbe54"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-23:** What was the training loss and validation loss at epoch 35?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6fe90a-3915-4373-8b20-b489979a26e2",
   "metadata": {
    "id": "9a6fe90a-3915-4373-8b20-b489979a26e2"
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc19bb2c-e388-4ea0-81c0-9e7f9c97e740",
   "metadata": {
    "id": "fc19bb2c-e388-4ea0-81c0-9e7f9c97e740"
   },
   "source": [
    "Evaluate the trained experimental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e2f07-fa6d-4355-94b0-82a5cfec4994",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd9e2f07-fa6d-4355-94b0-82a5cfec4994",
    "outputId": "f377751f-9b09-46e4-85e4-39fcee766f15"
   },
   "outputs": [],
   "source": [
    "experimental_test_acc = evaluate_model(\n",
    "    model=experimental_model, data_loader=test_loader\n",
    ")\n",
    "\n",
    "print(f\"Experimental model test accuracy: {experimental_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84fb71d-a9fe-4b08-ab4a-af377ca9d1bf",
   "metadata": {
    "id": "b84fb71d-a9fe-4b08-ab4a-af377ca9d1bf"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-24:** What is the test accuracy of the experimental model?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457a68a-e280-4390-a210-e9fa1163aac7",
   "metadata": {
    "id": "3457a68a-e280-4390-a210-e9fa1163aac7"
   },
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342ff8e-7776-4fbc-b09c-376bb93ca7ff",
   "metadata": {
    "id": "3342ff8e-7776-4fbc-b09c-376bb93ca7ff"
   },
   "source": [
    "## Performance Curves\n",
    "\n",
    "Now, we define plotting functions for the training and validation losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209873aa-ade6-4dea-a9f7-0c5818c41c5f",
   "metadata": {
    "id": "209873aa-ade6-4dea-a9f7-0c5818c41c5f"
   },
   "outputs": [],
   "source": [
    "def plot_training_values(\n",
    "    training_values: List,\n",
    "    validation_values: List,\n",
    "    title: str,\n",
    "    x_label: str,\n",
    "    y_label: str,\n",
    ") -> None:\n",
    "    plt.plot(\n",
    "        np.cumsum(training_values) / np.arange(1, len(training_values) + 1),\n",
    "        label=\"Training\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.cumsum(validation_values) / np.arange(1, len(validation_values) + 1),\n",
    "        label=\"Validation\",\n",
    "    )\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5c216-a94d-4dda-bab0-4bff4829d300",
   "metadata": {
    "id": "0dc5c216-a94d-4dda-bab0-4bff4829d300"
   },
   "source": [
    "Next, we define the function for plotting the loss or accuracy curves to compare the baseline model and the experimental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab7877-d9ad-42f2-aead-f505af2c052e",
   "metadata": {
    "id": "6aab7877-d9ad-42f2-aead-f505af2c052e"
   },
   "outputs": [],
   "source": [
    "def plot_model_values(\n",
    "    baseline_values: List,\n",
    "    experimental_values: List,\n",
    "    title: str,\n",
    "    x_label: str,\n",
    "    y_label: str,\n",
    ") -> None:\n",
    "    plt.plot(\n",
    "        np.cumsum(baseline_values) / np.arange(1, len(baseline_values) + 1),\n",
    "        label=\"Baseline\",\n",
    "    )  # cumulative moving average\n",
    "    plt.plot(\n",
    "        np.cumsum(experimental_values) / np.arange(1, len(experimental_values) + 1),\n",
    "        label=\"Experimental\",\n",
    "    )\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c8388-dd8b-4c54-86d3-ea6a0d16fd38",
   "metadata": {
    "id": "116c8388-dd8b-4c54-86d3-ea6a0d16fd38"
   },
   "source": [
    "Then, we plot the training and validation loss curves for the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff9b88-d231-456a-bee6-794fe859ed9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "bbff9b88-d231-456a-bee6-794fe859ed9c",
    "outputId": "eef87fb3-c6c8-4e6b-d42b-d57faf75a911"
   },
   "outputs": [],
   "source": [
    "plot_training_values(\n",
    "    training_values=baseline_train_loss,\n",
    "    validation_values=baseline_validation_loss,\n",
    "    title=\"Baseline Loss Curves\",\n",
    "    x_label=\"Step\",\n",
    "    y_label=\"Loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06d6de-5037-4841-b831-9ff97467b46b",
   "metadata": {
    "id": "6c06d6de-5037-4841-b831-9ff97467b46b"
   },
   "source": [
    "Then, we plot the training and validation accuracy curves for the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3f602-577e-4fd1-bab0-cc07a08fc621",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "b7d3f602-577e-4fd1-bab0-cc07a08fc621",
    "outputId": "845fbc36-d8ec-41ca-ced9-3ffd6accddca"
   },
   "outputs": [],
   "source": [
    "plot_training_values(\n",
    "    training_values=baseline_train_acc,\n",
    "    validation_values=baseline_validation_acc,\n",
    "    title=\"Baseline Accuracy Curves\",\n",
    "    x_label=\"Step\",\n",
    "    y_label=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d016fce-3de3-47bb-b5c6-bafd97c63eaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "4d016fce-3de3-47bb-b5c6-bafd97c63eaa",
    "outputId": "edfa31ce-558c-4782-c7ca-d6728589574d"
   },
   "outputs": [],
   "source": [
    "plot_training_values(\n",
    "    training_values=experimental_train_loss,\n",
    "    validation_values=experimental_validation_loss,\n",
    "    title=\"Experimental Loss Curves\",\n",
    "    x_label=\"Step\",\n",
    "    y_label=\"Loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3a10e-14ee-4515-ae94-fbcb94804914",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "a0c3a10e-14ee-4515-ae94-fbcb94804914",
    "outputId": "c611c75b-d927-4d16-d82f-4fa784e89e30"
   },
   "outputs": [],
   "source": [
    "plot_training_values(\n",
    "    training_values=experimental_train_acc,\n",
    "    validation_values=experimental_validation_acc,\n",
    "    title=\"Experimental Accuracy Curves\",\n",
    "    x_label=\"Step\",\n",
    "    y_label=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4eca5-e07c-49cb-849d-c9ea387e92d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "73e4eca5-e07c-49cb-849d-c9ea387e92d6",
    "outputId": "4165766d-916c-4ddc-cd13-cb54805de8a1"
   },
   "outputs": [],
   "source": [
    "plot_model_values(\n",
    "    baseline_train_loss,\n",
    "    experimental_train_loss,\n",
    "    title=\"Training Loss (Baseline vs Experimental)\",\n",
    "    x_label=\"Steps\",\n",
    "    y_label=\"Loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054b719-b6aa-4277-ab4f-4af11127f323",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "a054b719-b6aa-4277-ab4f-4af11127f323",
    "outputId": "c3bde633-0f54-4f8a-e8ea-65982920af29"
   },
   "outputs": [],
   "source": [
    "plot_model_values(\n",
    "    baseline_validation_loss,\n",
    "    experimental_validation_loss,\n",
    "    title=\"Validation Loss (Baseline vs Experimental)\",\n",
    "    x_label=\"Steps\",\n",
    "    y_label=\"Loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d6afc-1502-444e-9044-49426b6a7cd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "813d6afc-1502-444e-9044-49426b6a7cd1",
    "outputId": "84305b96-f0dd-49cf-ec93-aeadcb843816"
   },
   "outputs": [],
   "source": [
    "plot_model_values(\n",
    "    baseline_train_acc,\n",
    "    experimental_train_acc,\n",
    "    title=\"Training Accuracy (Baseline vs Experimental)\",\n",
    "    x_label=\"Steps\",\n",
    "    y_label=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8ff95-b64b-4986-bb43-a748eb580042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "c7a8ff95-b64b-4986-bb43-a748eb580042",
    "outputId": "467093bc-59ac-449d-c697-a3e4c67c1174"
   },
   "outputs": [],
   "source": [
    "plot_model_values(\n",
    "    baseline_validation_acc,\n",
    "    experimental_validation_acc,\n",
    "    title=\"Validation Accuracy (Baseline vs Experimental)\",\n",
    "    x_label=\"Steps\",\n",
    "    y_label=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e2b9b-9336-4967-8055-ffdffce1a297",
   "metadata": {
    "id": "8f5e2b9b-9336-4967-8055-ffdffce1a297"
   },
   "source": [
    "## Ablation on Experimental Model\n",
    "\n",
    "Now, let's play with our experimental model, and try to see if we could further improve its performance.\n",
    "\n",
    "Implement an image classifier neural network with the following specifications,\n",
    "\n",
    "* 2 layers with each layer having 500 neurons each\n",
    "* Each hidden layer will use ReLU function as its activation function\n",
    "* Use SGD as the optimization algorithm with the following learning rates\n",
    "  * $1 \\times 10^{-1}$\n",
    "  * $1 \\times 10^{-2}$\n",
    "  * $1 \\times 10^{-3}$\n",
    "  * $1 \\times 10^{-4}$\n",
    "\n",
    "Train for 50 epochs with mini-batch size 100. This will serve as our challenger or experimental model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3aa906-dc14-409c-aa15-cd0ddba96c30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c3aa906-dc14-409c-aa15-cd0ddba96c30",
    "outputId": "52fa9392-543b-4b56-aebe-98caaa7a04bf"
   },
   "outputs": [],
   "source": [
    "# to do: define the list of learning rates\n",
    "learning_rates = [...]\n",
    "\n",
    "results = dict()\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    # to do: initialize an experimental model for the current learning rate\n",
    "    experimental_model = ...\n",
    "\n",
    "    # to do: switch to GPU\n",
    "    experimental_model = ...\n",
    "\n",
    "    print(f\"Training model with learning rate = {learning_rate}\")\n",
    "\n",
    "    # to do: run the model training for the given learning rate\n",
    "    ...\n",
    "\n",
    "    # to do: evaluate the trained model\n",
    "    ...\n",
    "    \n",
    "    print(f\"Test accuracy: {experimental_test_acc:.4f}\")\n",
    "\n",
    "    # store the results for later retrieval\n",
    "    results[f\"lr-{learning_rate}\"] = dict(\n",
    "        train_acc=experimental_train_acc,\n",
    "        train_loss=experimental_train_loss,\n",
    "        validation_loss=experimental_validation_loss,\n",
    "        validation_acc=experimental_validation_acc,\n",
    "        test_accuracy=experimental_test_acc\n",
    "    )\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee8093c-3ac0-44ce-81c6-0eb0d50d3f84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eee8093c-3ac0-44ce-81c6-0eb0d50d3f84",
    "outputId": "23dba6d8-f43b-45a3-af54-b2b4161b8033"
   },
   "outputs": [],
   "source": [
    "for learning_rate in learning_rates:\n",
    "    plot_training_values(\n",
    "        training_values=results[f\"lr-{learning_rate}\"][\"train_acc\"],\n",
    "        validation_values=results[f\"lr-{learning_rate}\"][\"validation_acc\"],\n",
    "        title=f\"Accuracy Curves (lr={learning_rate})\",\n",
    "        x_label=\"Step\",\n",
    "        y_label=\"Accuracy\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc234798-247f-4b99-a2b6-d80c8028aed5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dc234798-247f-4b99-a2b6-d80c8028aed5",
    "outputId": "f795379d-48c4-429f-f9e0-08d379ecc2af"
   },
   "outputs": [],
   "source": [
    "for learning_rate in learning_rates:\n",
    "    plot_training_values(\n",
    "        training_values=results[f\"lr-{learning_rate}\"][\"train_loss\"],\n",
    "        validation_values=results[f\"lr-{learning_rate}\"][\"validation_loss\"],\n",
    "        title=f\"Loss Curves (lr={learning_rate})\",\n",
    "        x_label=\"Step\",\n",
    "        y_label=\"Loss\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MCTGTF2sR-6i",
   "metadata": {
    "id": "MCTGTF2sR-6i"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-25:** What was the best test accuracy across the 4 learning rates used for the model? What was the learning rate used?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98LPjJD7SF1A",
   "metadata": {
    "id": "98LPjJD7SF1A"
   },
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ulWtUdTECH",
   "metadata": {
    "id": "f6ulWtUdTECH"
   },
   "source": [
    "<span style=\"color:red;\">**Question 6-26:** Based on the loss curves, what can you say about the model when it was trained with a learning rate of 0.0001?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iEEhHv7NTRkt",
   "metadata": {
    "id": "iEEhHv7NTRkt"
   },
   "source": [
    "**Answers**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0605083-0e06-4d1d-b949-08a9b3f3ac85",
   "metadata": {},
   "source": [
    "### <center>fin</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d5eee9-8cfd-44b9-9194-f6ce226c33d5",
   "metadata": {},
   "source": [
    "\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->\n",
    "<sup>written by Abien Fred Agarap</sup> <br>\n",
    "<sup>for comments, corrections, suggestions, please email:</sup><sup> abienfred.agarap@gmail.com</sup><br>\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
