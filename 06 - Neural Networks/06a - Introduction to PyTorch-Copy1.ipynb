{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2238e5d8-2f17-4608-8461-873e830a35ef",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "To extend the SGDClassifier from the previous notebook, there will be a jumpy from sklearn to PyTorch library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15134dd4-2d65-4081-b548-11cf4c5ebfb7",
   "metadata": {},
   "source": [
    "## Instructions for All Labs\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* Some markdown cells contain questions.\n",
    "  * For questions <span style=\"color:red;\">colored in red</span>, you must submit your answers in the corresponding Assignment in the course page. Make sure that you enter your responses in the item with the matching question code. Answers that do not follow the prescribed format will automatically be marked wrong by the checker.\n",
    "  * For questions <span style=\"color:green;\">colored in green</span>, you don't have to submit your answers, but you must think about these questions as they will help enrich your understanding of the concepts covered in the labs.\n",
    "* You are expected to search how to some functions work on the Internet or via the docs. \n",
    "* You may add new cells for \"scrap work\".\n",
    "* The notebooks will undergo a \"Restart and Run All\" command, so make sure that your code is working properly.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d51607-4718-4dd5-8297-4ff40697d3e4",
   "metadata": {},
   "source": [
    "This notebook provides a short introduction to PyTorch, for a more in-depth introduction, refer to the official PyTorch [website](https://pytorch.org/tutorials/). \n",
    "\n",
    "PyTorch is an open-source machine learning library developed by Facebook, its primary usage is for implementing neural networks. But this does not mean that it is exclusive to neural networks. It can be used for general-purpose scientific computing, which is beyond the scope of this notebook.\n",
    "\n",
    "You have to install PyTorch,\n",
    "\n",
    "```shell\n",
    "pip install torch\n",
    "```\n",
    "\n",
    "To take advantage of a GPU, it is recommended to upload this notebook to [Google Colab](https://colab.research.google.com/), but please do not use any code-generative features of the platform so you can actually learn the materials and concepts. [Lightning AI](https://lightning.ai/) is a nice alternative, but it usually requires account verification (within 24-48 hours). \n",
    "\n",
    "Note that Colab may have a PyTorch installation readily available.\n",
    "\n",
    "## PyTorch Basics\n",
    "\n",
    "We start with reviewing the basic concepts of PyTorch. Familiarity with `numpy` is recommended as it shares similar concepts with PyTorch. If you are not familiar with `numpy`, you may refer to their [official guide](https://numpy.org/devdocs/user/quickstart.html). \n",
    "\n",
    "Let's check the version of the package we have installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d060e2f-9295-438d-9115-882b5fdbfdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1191591-cd64-4e0d-8708-4854af09e99c",
   "metadata": {},
   "source": [
    "The `+cu124` indicates that the version installed is capable of using the Nvidia GPU in my machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a40a1d-c918-403c-ab6d-bc048c53df14",
   "metadata": {},
   "source": [
    "To control the stochasticity of pseudorandom number generator, we should set the seed for the environment. For completeness sake, we can also set the seed for other libraries as some functions under the hood might be using them as well. There are also other functions to set the determinism of pseudorandom number generator in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a396cced-2657-4aa6-9ffa-954fbff002a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  # Python built-in library\n",
    "import numpy as np\n",
    "\n",
    "np.__version__  # for sanity checking\n",
    "\n",
    "seed = 73\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# benchmarking results to the library \n",
    "# computing the best algorithm to use for your hardware\n",
    "torch.backends.cudnn.benchmark = False  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a495fc52-522a-4b69-a901-86fe83db5212",
   "metadata": {},
   "source": [
    "To initialize a tensor (a generalized mathematical object for structures, i.e. a scalar is a 0-d tensor, a vector is a 1-d tensor, and a matrix is a 2-d tensor), we can use the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985068d2-d456-4d65-baab-22d25de2510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]])\n"
     ]
    }
   ],
   "source": [
    "initial_values = torch.empty(5, 3)\n",
    "\n",
    "print(initial_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972651c9-fddb-4923-8d4b-d55d8c095706",
   "metadata": {},
   "source": [
    "The above initialization does virtually the same thing as the following function,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722b2f31-36fc-4843-b0d2-5c347fca6dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5286, 0.1616, 0.8870],\n",
      "        [0.6216, 0.0459, 0.3856],\n",
      "        [0.2258, 0.7837, 0.2052],\n",
      "        [0.1868, 0.9023, 0.9923],\n",
      "        [0.4589, 0.7409, 0.4562]])\n"
     ]
    }
   ],
   "source": [
    "initial_values = torch.rand(5, 3)\n",
    "\n",
    "print(initial_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d39c6-f627-434b-a4f9-29e3b52f150f",
   "metadata": {},
   "source": [
    "To check the size or shape of the tensor,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35567d9-7531-409f-90df-407fa2c0388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(initial_values.size())\n",
    "print(initial_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb76bfbb-57de-49a6-ae77-1c2590e31335",
   "metadata": {},
   "source": [
    "To perform arithmetic operations in PyTorch, we may use the basic Python operations or the PyTorch-specific functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe66c44-1bec-4859-87c7-5427a1c907e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5286, 1.1616, 1.8870],\n",
      "        [1.6216, 1.0459, 1.3856],\n",
      "        [1.2258, 1.7837, 1.2052],\n",
      "        [1.1868, 1.9023, 1.9923],\n",
      "        [1.4589, 1.7409, 1.4562]])\n",
      "\n",
      "tensor([[1.5286, 1.1616, 1.8870],\n",
      "        [1.6216, 1.0459, 1.3856],\n",
      "        [1.2258, 1.7837, 1.2052],\n",
      "        [1.1868, 1.9023, 1.9923],\n",
      "        [1.4589, 1.7409, 1.4562]])\n",
      "tensor([[-0.4714, -0.8384, -0.1130],\n",
      "        [-0.3784, -0.9541, -0.6144],\n",
      "        [-0.7742, -0.2163, -0.7948],\n",
      "        [-0.8132, -0.0977, -0.0077],\n",
      "        [-0.5411, -0.2591, -0.5438]])\n",
      "tensor([[0.5286, 0.1616, 0.8870],\n",
      "        [0.6216, 0.0459, 0.3856],\n",
      "        [0.2258, 0.7837, 0.2052],\n",
      "        [0.1868, 0.9023, 0.9923],\n",
      "        [0.4589, 0.7409, 0.4562]])\n",
      "tensor([[0.5286, 0.1616, 0.8870],\n",
      "        [0.6216, 0.0459, 0.3856],\n",
      "        [0.2258, 0.7837, 0.2052],\n",
      "        [0.1868, 0.9023, 0.9923],\n",
      "        [0.4589, 0.7409, 0.4562]])\n"
     ]
    }
   ],
   "source": [
    "print(initial_values + 1)\n",
    "print()\n",
    "print(torch.add(initial_values, 1))\n",
    "\n",
    "# try torch.sub(), torch.mul(), torch.div()\n",
    "print(torch.sub(initial_values,1))\n",
    "print(torch.mul(initial_values,1))\n",
    "print(torch.div(initial_values,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997314b-17a5-4317-8def-33f01c69b340",
   "metadata": {},
   "source": [
    "There's also an in-place operation where we use the function with underscore suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6568ecb3-b373-4029-9f19-b1b96b29366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5286, 1.1616, 1.8870],\n",
      "        [1.6216, 1.0459, 1.3856],\n",
      "        [1.2258, 1.7837, 1.2052],\n",
      "        [1.1868, 1.9023, 1.9923],\n",
      "        [1.4589, 1.7409, 1.4562]])\n",
      "tensor([[0.5286, 0.1616, 0.8870],\n",
      "        [0.6216, 0.0459, 0.3856],\n",
      "        [0.2258, 0.7837, 0.2052],\n",
      "        [0.1868, 0.9023, 0.9923],\n",
      "        [0.4589, 0.7409, 0.4562]])\n",
      "\n",
      "tensor([[1.5286, 1.1616, 1.8870],\n",
      "        [1.6216, 1.0459, 1.3856],\n",
      "        [1.2258, 1.7837, 1.2052],\n",
      "        [1.1868, 1.9023, 1.9923],\n",
      "        [1.4589, 1.7409, 1.4562]])\n",
      "tensor([[1.5286, 1.1616, 1.8870],\n",
      "        [1.6216, 1.0459, 1.3856],\n",
      "        [1.2258, 1.7837, 1.2052],\n",
      "        [1.1868, 1.9023, 1.9923],\n",
      "        [1.4589, 1.7409, 1.4562]])\n"
     ]
    }
   ],
   "source": [
    "print(initial_values.add(1))\n",
    "print(initial_values)\n",
    "\n",
    "print()\n",
    "\n",
    "print(initial_values.add_(1))\n",
    "print(initial_values)  # notice anything?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7625427b-89ca-4637-8d08-d61d47e2f718",
   "metadata": {},
   "source": [
    "Slicing is the same as numpy,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "204de3b5-0ab6-42c6-8fe6-efbbaca1f003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5286, 1.6216, 1.2258, 1.1868, 1.4589])\n",
      "tensor([1.1616, 1.0459, 1.7837, 1.9023, 1.7409])\n",
      "tensor([1.8870, 1.3856, 1.2052, 1.9923, 1.4562])\n",
      "tensor([1.5286, 1.1616, 1.8870])\n"
     ]
    }
   ],
   "source": [
    "print(initial_values[:, 0])\n",
    "print(initial_values[:, 1])\n",
    "print(initial_values[:, 2])\n",
    "print(initial_values[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c892b4-b33b-4510-8170-626a9bc59bae",
   "metadata": {},
   "source": [
    "Initialize one-tensor or zero-tensor,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7bce50a-241c-4819-9660-1d7cb49ad368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(5, 3)\n",
    "zeros = torch.zeros(5, 3)\n",
    "\n",
    "print(ones)\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2693a4-6443-4f9c-ac01-93642035df2e",
   "metadata": {},
   "source": [
    "Perform matrix transpose,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55ed820-009d-4616-8b75-ad65d79c5acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5286, 1.6216, 1.2258, 1.1868, 1.4589],\n",
      "        [1.1616, 1.0459, 1.7837, 1.9023, 1.7409],\n",
      "        [1.8870, 1.3856, 1.2052, 1.9923, 1.4562]])\n"
     ]
    }
   ],
   "source": [
    "# 5x3 matrix transposed is 3x5 matrix\n",
    "# we transpose using the indices\n",
    "print((initial_values.transpose(1, 0)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80253f06-6eb5-4857-98b1-848a3a880802",
   "metadata": {},
   "source": [
    "Use some transformation functions like logistic and softmax,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007176f9-7c8b-4ad5-857a-c280fcc4f303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8218, 0.7616, 0.8684],\n",
      "        [0.8350, 0.7400, 0.7999],\n",
      "        [0.7731, 0.8562, 0.7694],\n",
      "        [0.7662, 0.8701, 0.8800],\n",
      "        [0.8114, 0.8508, 0.8110]])\n",
      "tensor([[0.3201, 0.2218, 0.4581],\n",
      "        [0.4252, 0.2391, 0.3358],\n",
      "        [0.2684, 0.4688, 0.2629],\n",
      "        [0.1893, 0.3871, 0.4236],\n",
      "        [0.3009, 0.3990, 0.3001]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\AppData\\Local\\Temp\\ipykernel_14836\\1273975213.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(torch.nn.functional.softmax(initial_values))\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.functional.sigmoid(initial_values))\n",
    "print(torch.nn.functional.softmax(initial_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc16df-89de-4885-8f1c-025ba205c841",
   "metadata": {},
   "source": [
    "Recall the formulas being,\n",
    "\n",
    "$\\sigma(z) = \\dfrac{1}{1 + \\exp(-z)}$\n",
    "\n",
    "for logistic function (sigmoid). \n",
    "\n",
    "And the following for softmax,\n",
    "\n",
    "$\\sigma(z) = \\dfrac{\\exp(z)}{\\sum \\exp(z)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3cc6c7-41df-4304-ab4d-bb5af69eefc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8218, 0.7616, 0.8684],\n",
      "        [0.8350, 0.7400, 0.7999],\n",
      "        [0.7731, 0.8562, 0.7694],\n",
      "        [0.7662, 0.8701, 0.8800],\n",
      "        [0.8114, 0.8508, 0.8110]])\n",
      "tensor([[0.3201, 0.2218, 0.4581],\n",
      "        [0.4252, 0.2391, 0.3358],\n",
      "        [0.2684, 0.4688, 0.2629],\n",
      "        [0.1893, 0.3871, 0.4236],\n",
      "        [0.3009, 0.3990, 0.3001]])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    1 / (1 + torch.exp(-initial_values))\n",
    ")\n",
    "\n",
    "print(\n",
    "    torch.exp(initial_values) / torch.sum(torch.exp(initial_values), axis=1, keepdims=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff996858-c3e3-4e06-bc98-50c49557a0b0",
   "metadata": {},
   "source": [
    "However, performing softmax this way is numerically unstable. As the values become large, there is an overflow issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb06dc6-4dac-4faf-9c23-eb42989ee726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., nan, 0.])\n"
     ]
    }
   ],
   "source": [
    "samples = torch.Tensor([10, 2, 10_000, 4])\n",
    "\n",
    "# axis=0 since this is only a vector\n",
    "print(\n",
    "    torch.exp(samples) / (torch.sum(torch.exp(samples), axis=0, keepdims=True))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f4e69-493d-4a6c-990a-fd229d59f0f9",
   "metadata": {},
   "source": [
    "How do we resolve this? Use max-value subtraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daab0462-b94c-46ae-a00f-960cc312ab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1749, 0.1749, 0.4754, 0.1749])\n"
     ]
    }
   ],
   "source": [
    "samples = torch.Tensor([10, 2, 10_000, 4])\n",
    "samples = torch.exp(samples - torch.max(samples))\n",
    "\n",
    "# axis=0 since this is only a vector\n",
    "print(\n",
    "    torch.exp(samples) / (torch.sum(torch.exp(samples), axis=0, keepdims=True))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469b3c8b-59fc-492d-b8c1-5e2a61505a07",
   "metadata": {},
   "source": [
    "To perform some linear algebra operations,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55da6992-d902-4104-9d00-35e821d2ebe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.2467, 6.3083, 6.2200, 7.7833, 7.0001],\n",
       "        [6.3083, 5.6433, 5.5233, 6.6746, 6.2042],\n",
       "        [6.2200, 5.5233, 6.1368, 7.2490, 6.6486],\n",
       "        [7.7833, 6.6746, 7.2490, 8.9964, 7.9442],\n",
       "        [7.0001, 6.2042, 6.6486, 7.9442, 7.2795]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(\n",
    "    initial_values, initial_values.transpose(1, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41949bcd-47a4-4e4e-abf0-6de18538577a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## inner product\n",
    "torch.dot(samples, (samples - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6d2c088-910f-466c-9adc-15b8d852bccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6920, 2.3756, 2.4773, 2.9994, 2.6981])\n",
      "tensor([2.6920, 2.3756, 2.4773, 2.9994, 2.6981])\n",
      "tensor([2.6920, 2.3756, 2.4773, 2.9994, 2.6981])\n"
     ]
    }
   ],
   "source": [
    "## L2 norm\n",
    "print(initial_values.norm(dim=1, p=2))\n",
    "print(torch.linalg.norm(initial_values, dim=1, ord=2))\n",
    "print(initial_values.pow(2).sum(dim=1).sqrt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab81a24-7b04-4bec-9407-6202bb60137f",
   "metadata": {},
   "source": [
    "Stacking tensors,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fad5992a-b4a4-42d4-aeec-f66514833563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4051, 0.5739, 0.8014, 0.3398],\n",
      "        [0.3198, 0.3518, 2.7384, 0.0552]])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4)\n",
    "b = torch.randn(4)\n",
    "stacked_tensors = torch.stack([a, b])\n",
    "print(stacked_tensors)\n",
    "print(stacked_tensors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20448dd3-bfa1-4838-9934-cc52a5161fb7",
   "metadata": {},
   "source": [
    "Flatten a tensor, e.g. from 2x4 tensor to a 8x1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b32c60ca-bfb9-4b1c-bc0d-20ecb4bdc456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4051, 0.5739, 0.8014, 0.3398, 0.3198, 0.3518, 2.7384, 0.0552])\n",
      "tensor([1.4051, 0.5739, 0.8014, 0.3398, 0.3198, 0.3518, 2.7384, 0.0552])\n"
     ]
    }
   ],
   "source": [
    "print(stacked_tensors.view(-1))\n",
    "print(stacked_tensors.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a9c75-5875-4ca0-92a0-924b5cb6304a",
   "metadata": {},
   "source": [
    "Convert a numpy array to a tensor,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa81d1e7-84c6-48f5-b199-8a83a4c45f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.57681305  2.1311088   2.44021967  0.26332687 -1.49612065 -0.03673531\n",
      "   0.43069579 -1.52947433 -0.73025968  1.05131524]\n",
      " [ 1.61979267 -1.60501337  0.33100953 -0.21095236  0.2981767  -1.14607352\n",
      "   0.57536202 -0.36390663  0.03639919 -0.52056399]]\n",
      "tensor([[ 0.5768,  2.1311,  2.4402,  0.2633, -1.4961, -0.0367,  0.4307, -1.5295,\n",
      "         -0.7303,  1.0513],\n",
      "        [ 1.6198, -1.6050,  0.3310, -0.2110,  0.2982, -1.1461,  0.5754, -0.3639,\n",
      "          0.0364, -0.5206]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "samples = np.random.randn(2, 10)\n",
    "print(samples)\n",
    "\n",
    "samples = torch.from_numpy(samples)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873fc89-fbf3-4b63-a83b-2b5fe8a21396",
   "metadata": {},
   "source": [
    "`torch.from_numpy()` vs `torch.Tensor()`\n",
    "\n",
    "* `torch.Tensor()` creates a new copy of the array, and automatically converts the array to float32\n",
    "* `torch.from_numpy()` does not create a new copy, and preserves the dtype of the array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e43396-79c2-4f35-828f-b23aa0e82812",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Given a list of three tensors, with each tensor representing a set of hypothetical model outputs, put them together so that each row would have all outputs for a given sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "993efdd6-fdec-42bd-924d-f56de80a17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = torch.Tensor(\n",
    "    [\n",
    "        [0.2562, 0.1650, 0.0918, 0.0045, 0.0175, 0.1096, 0.0831, 0.2002, 0.0532, 0.0188],\n",
    "        [0.0553, 0.1154, 0.0719, 0.0945, 0.0705, 0.2141, 0.0665, 0.0610, 0.2023, 0.0487]\n",
    "    ]\n",
    ")\n",
    "\n",
    "out_2 = torch.Tensor(\n",
    "    [\n",
    "        [0.0942, 0.0448, 0.0929, 0.0316, 0.0296, 0.0272, 0.4189, 0.0804, 0.0988, 0.0816],\n",
    "        [0.2645, 0.0424, 0.0199, 0.1344, 0.0226, 0.1131, 0.2144, 0.1160, 0.0421, 0.0306]\n",
    "    ]\n",
    ")\n",
    "\n",
    "out_3 = torch.Tensor(\n",
    "    [\n",
    "        [0.1159, 0.1263, 0.1011, 0.0870, 0.1503, 0.0259, 0.0609, 0.1611, 0.0082, 0.1633],\n",
    "        [0.1230, 0.0577, 0.3204, 0.0145, 0.0699, 0.0975, 0.0466, 0.1191, 0.0841, 0.0671]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d418e-501e-4b8b-86f7-01ac33ab12e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 10])\n",
      "tensor([[[0.1165, 0.1064, 0.0989, 0.0906, 0.0918, 0.1006, 0.0980, 0.1102,\n",
      "          0.0951, 0.0919],\n",
      "         [0.0988, 0.0940, 0.0986, 0.0928, 0.0926, 0.0924, 0.1367, 0.0974,\n",
      "          0.0992, 0.0975],\n",
      "         [0.1015, 0.1025, 0.1000, 0.0986, 0.1050, 0.0927, 0.0960, 0.1062,\n",
      "          0.0911, 0.1064]],\n",
      "\n",
      "        [[0.0955, 0.1014, 0.0971, 0.0993, 0.0969, 0.1119, 0.0965, 0.0960,\n",
      "          0.1106, 0.0948],\n",
      "         [0.1175, 0.0941, 0.0920, 0.1032, 0.0922, 0.1010, 0.1117, 0.1013,\n",
      "          0.0941, 0.0930],\n",
      "         [0.1020, 0.0955, 0.1242, 0.0915, 0.0967, 0.0994, 0.0945, 0.1016,\n",
      "          0.0981, 0.0964]]])\n"
     ]
    }
   ],
   "source": [
    "# TO DO:\n",
    "#  1. Simulate predicted probability distributions by passing them through softmax\n",
    "#  2. Stack the tensors to get a tensor of shape 2x3x10 (`torch.Size([2, 3, 10])`)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#applying softmax to each tensor\n",
    "out_1_softmax = F.softmax(out_1, dim=-1)\n",
    "out_2_softmax = F.softmax(out_2, dim=-1)\n",
    "out_3_softmax = F.softmax(out_3, dim=-1)\n",
    "\n",
    "#stacking \n",
    "stacked_tensor = torch.stack([out_1_softmax, out_2_softmax, out_3_softmax], dim=1)\n",
    "\n",
    "print(stacked_tensor.shape)\n",
    "print(stacked_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f7d6f4-d980-46a0-934b-1c43cb406bdb",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">**Question 6-1:** What are the probability values for the first instance (first row) by the the third hypothetical model?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "842422d2-cbb0-45a6-9af3-67b00f20fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1015, 0.1025, 0.1000, 0.0986, 0.1050, 0.0927, 0.0960, 0.1062, 0.0911,\n",
      "        0.1064])\n"
     ]
    }
   ],
   "source": [
    "probability_value = out_3_softmax[0]\n",
    "print(probability_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de942e-9842-44e0-bc45-c1b284f7e8d7",
   "metadata": {},
   "source": [
    "**Answer**:  [0.1015, 0.1025, 0.1000, 0.0986, 0.1050, 0.0927, 0.0960, 0.1062, 0.0911,\n",
    "        0.1064]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c867256f-b4cd-402e-97d4-fcd5c94c4f7e",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">**Question 6-1:** What are the probability values for the second instance (second row) by the the second hypothetical model?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "573d0797-d552-4918-afd4-8d1d6f442d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1175, 0.0941, 0.0920, 0.1032, 0.0922, 0.1010, 0.1117, 0.1013, 0.0941,\n",
      "        0.0930])\n"
     ]
    }
   ],
   "source": [
    "probability_value = out_2_softmax[1]\n",
    "print(probability_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea1e73-38f2-46e1-b75a-a06eb79ae2b4",
   "metadata": {},
   "source": [
    "**Answer**: [0.1175, 0.0941, 0.0920, 0.1032, 0.0922, 0.1010, 0.1117, 0.1013, 0.0941,\n",
    "        0.0930]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2634d-b98b-4789-9314-15b09b9a23f9",
   "metadata": {},
   "source": [
    "<span style=\"color:red;\">**Question 6-1:** What are the probability values for the first instance (first row) by the the first hypothetical model?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bea24748-e2c8-4148-b1e1-904b9cd3ea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1165, 0.1064, 0.0989, 0.0906, 0.0918, 0.1006, 0.0980, 0.1102, 0.0951,\n",
      "        0.0919])\n"
     ]
    }
   ],
   "source": [
    "probability_value = out_1_softmax[0]\n",
    "print(probability_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d8fc05-5b42-4e32-93c4-45208f18f149",
   "metadata": {},
   "source": [
    "**Answer**: [0.1165, 0.1064, 0.0989, 0.0906, 0.0918, 0.1006, 0.0980, 0.1102, 0.0951,\n",
    "        0.0919]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06088554-1701-4c2c-871e-d1c3dbca9c56",
   "metadata": {},
   "source": [
    "Other useful functions that you may explore,\n",
    "* torch.nn.BCELoss is the binary cross entropy\n",
    "* torch.nn.BCEWithLogitsLoss BCE without logistic function.\n",
    "* torch.nn.CrossEntropyLoss is the softmax cross entropy loss\n",
    "* torch.nn.MSELoss is the Mean Squared Error \n",
    "* torch.nn.NLLLoss is the negative log likelihood (log likelihood without softmax computation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
